<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h2 id="overfeatintegrated-recognition-localization-and-detection-using-convolutional-networks"><a href="http://arxiv.org/abs/1312.6229">OverFeat:Integrated Recognition, Localization and Detection using Convolutional Networks</a></h2>
<h2 id="overfeat笔记"><strong><em>OverFeat笔记</em></strong></h2>
<p>文章链接：http://arxiv.org/abs/1312.6229 源码：http://cilvr.nyu.edu/doku.php?id=software:overfeat:start</p>
<h2 id="一句话概括本文内容"><strong><em>一句话概括本文内容</em></strong></h2>
<p>用CNN解决了ImageNet的<strong><em>分类和定位的问题</em></strong>，获得了2013年该项目的冠军。</p>
<h2 id="本文核心思想"><strong><em>本文核心思想</em></strong></h2>
<p>有两点，<strong><em>其中第二点是亮点</em></strong>： 1. 特征共享：首先在分类问题上训练出来模型，然后Fix住卷积层，来对定位模型进行fine tuning，最后对应1k个类别做了1k个定位的模型。 2. “快速”滑动窗口：为何要用滑动窗口？对于分类，通过多视角和多尺度来提高分类的置信度；对于定位，解决了多物体以及多尺度的问题。如何提高滑动窗口的效率？不在原始图片上做滑动窗口，而是在最后一个pooling层上面做滑动窗口。</p>
<h2 id="模型"><strong><em>模型</em></strong></h2>
<p>基本同AlexNet，主要是缩小了前两层的卷积核和步长，使得神经元从60m变成了144m。本质上是加强了网络的表达能力，训练时间会变长，但是准确率会升高。</p>
<h2 id="简述流程"><strong><em>简述流程</em></strong></h2>
<ol style="list-style-type: decimal">
<li>初始化模型后，进来一张图片，利用滑动窗口技术提取出来多个patch。</li>
<li>对于每个patch，用分类模型确定好类别，然后使用对用的定位模型来确定物体的位置。</li>
<li>根据分类的分数可以选出k个候选的patch</li>
<li>对patch进行合并</li>
</ol>
<p align="center">
<img src="http://i.imgur.com/SuoCSxl.png" width="600" >
</p>
<h2 id="快速滑动窗口"><strong><em>快速滑动窗口</em></strong></h2>
<p>也就是<strong><em>在最后一个pool层上做滑动窗口</em></strong>。 本质上，<strong><em>在pool做小步长的滑动窗口和在原始图片上做大步长的滑动窗口，从<a href="">识别效果</a>上来说几乎是等价的</em></strong>，但是在效率上存在极大的差别——所以这里的“快速”本质上是利用了CNN卷积层和下采样层的空间对应关系来减少计算。</p>
<p align="center">
<img src="http://i.imgur.com/QHPlEo3.png" width="600" >
</p>
<h2 id="其他一些注意点"><strong><em>其他一些注意点</em></strong></h2>
<p>对于分类模型，训练只使用单个尺度（221＊221）进行训练，测试时候不改变网络架构，却是<strong><em>使用多个尺度进行输入的——于是导致了网络的输出由1维变成了2维（其实就是滑动窗口）</em></strong></p>
<p>训练分类模型只是使用了<strong><em>单尺度</em></strong>，但后面训练定位模型时候用到了多尺度，个人认为是为了增加样本——因为训练1k个定位模型的话，每类的样本太少了。</p>
<p>本文提出的“<strong><em>测试时实现多视角多尺度</em></strong>”方法，其本质上就是<strong><em>滑动窗口——多视角≈滑动到不同的位置，多视角≈大小不一的窗口</em></strong>。只是利用CNN的固有属性以及一些技巧，减少了测试时候的运算量。</p>
</body>
</html>
