<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h2 id="long-term-recurrent-convolutional-networks-for-visual-recognition-and-descriptioncode"><a href="http://jeffdonahue.com/lrcn/"><strong>Long-term Recurrent Convolutional Networks for Visual Recognition and Description</strong></a>/<a href="http://www.eecs.berkeley.edu/~lisa_anne/LRCN_video">Code</a> <br/></h2>
<p>They propose a <span style="color:red"><em>Long-term recurrent convolutional networks(LRCNs)</em></span> which combines CNN and long-range temporal recursion and is end-to-end trainable.<br/></p>
<p><span style="color:red">Feature extraction: </span>Given visual inputs <span class="math inline">\(v_t, t\in T\)</span>, first they use CNN to get feature transformation <span class="math inline">\(\phi_V(v_t)\)</span>, where <span class="math inline">\(V\)</span> is the parameter of CNN network, to get a fixed-length vector representation <span class="math inline">\(\phi_t \in R^d; &lt;\phi_1, ..., \phi_T&gt;\)</span>. <br/> <span style="color:red">Sequence generation: </span> two layer LSTM map the input features to the output <span class="math inline">\(z_t\)</span>, which <span class="math inline">\(z_t=h_t\)</span>. And <span class="math inline">\(h_1=f_W(x_1,h_0)=f_W(x_1,0)\)</span>, then <span class="math inline">\(h_2=f_W(x_2,h_1)\)</span>, etc., up to <span class="math inline">\(h_T\)</span>.<br/> <span style="color:red">Final prediction: </span> Use softmax over the ouputs <span class="math inline">\(z_t\)</span>. <span class="math inline">\(P(y_t=c)=\frac{exp(W_{zc}z_{t,c}+b_c)}{\sum_{c1\in C}exp(W_{zc}z_{t,c`}+b_c)}\)</span>.<br/> <span style="color:red">Objective function: </span> Minimize the negative log likelihood <span class="math inline">\(L(V,W)=-logP_{V,W}(y_t|x_{1:t},y_{1:t-1})\)</span> of the training data <span class="math inline">\((x,y)\)</span>.<br/></p>
</body>
</html>
