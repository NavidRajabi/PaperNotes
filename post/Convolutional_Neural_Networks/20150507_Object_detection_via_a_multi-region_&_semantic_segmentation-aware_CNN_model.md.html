<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<p>今天连看了Fast RCNN和这一篇，一开始以为这篇会是Fast RCNN的加强版。看了之后发现不是，这篇提出的框架更像是SPP-Net的加强版，因为这篇并没有实现joint training，不同的步骤还是分开来跑的。不禁让人想，如果能够结合这篇和Fast RCNN的所有技巧，VOC07的mAP会不会上80%了啊。。Detection进步确实太快了。</p>
<h2 id="motivation"><strong><em>motivation</em></strong></h2>
<p>对于某个region proposal来说，<strong><em>如何抽取比较好的特征？是否需要context辅助？是否需要考虑遮挡问题？</em></strong></p>
<p>上述就是作者的motivation，如Figure 1，子图1的羊需要context，子图2的船不要context，子图3的车需要考虑遮挡问题。</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/%E5%B0%8FQ%E6%88%AA%E5%9B%BE-20150517151916.png" width="400" >
</p>
<p>所以该paper的核心研究内容是，如何<strong><em>更好地localize一个object</em></strong>，并抽取<strong><em>好的特征</em></strong>。 作者做了三件事：</p>
<ol style="list-style-type: decimal">
<li>提出一个<strong><em>multi-region CNN </em></strong>来增强特征</li>
<li>提出一个<strong><em>semantic segmentation-aware CNN</em></strong>再进一步增强特征</li>
<li>提出一个<strong><em>CNN-based regression</em></strong>方法，另外还提出<strong><em>2个tricks来refine最后的定位</em></strong>。</li>
</ol>
<p>下面分开一点一点说。</p>
<h3 id="multi-region-cnn"><strong><em>Multi-region CNN</em></strong></h3>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/%E5%B0%8FQ%E6%88%AA%E5%9B%BE-20150517151924.png" width="600" >
</p>
<p>Figure 2所示便是Multi-region CNN（简称为MR-CNN）在single scale下的给某个object proposal提取特征的过程，<strong><em>用AlexNet举例，提取一个proposal的步骤是</em></strong></p>
<ol style="list-style-type: decimal">
<li>用<strong><em>前5个卷积层</em></strong>提取到全图的在<a href="">conv5时候的feature map</a></li>
<li>对于某个object proposal，将观察范围做<a href="">一定的形变和修改</a>得到<a href="">不同的region</a>，比如图中出来4个不同的region。</li>
<li>将region投影到<a href="">conv5 feature map</a>上，<a href="">crop出来对应的区域</a>，然后用一个单层的SPP layer下采样到同样的大小</li>
<li>然后各自经过<a href="">两个全连接层进一步提取特征</a></li>
<li>最后所有特征<a href="">连在一起得到一个长特征</a>。</li>
</ol>
<p>可以看出，跟SPP提取proposal特征的过程很像，多出来是<a href="">第2步</a>，也就是这里的主要贡献点。</p>
<p><strong><em>作者一共提出了4种共10个region：</em></strong></p>
<ol style="list-style-type: decimal">
<li>原始的region，就是原来的那个<a href="">object proposal</a>的位置，对应Figure的中<a href=""><span class="math inline">\(a\)</span></a></li>
<li><a href="">截半</a>，对应Figure3的<a href=""><span class="math inline">\(b-e\)</span></a></li>
<li><a href="">中心区域</a>，对应<a href=""><span class="math inline">\(g\)</span></a>和<span class="math inline">\(h\)</span></li>
<li><a href="">边界区域</a>，对应<a href=""><span class="math inline">\(i\)</span></a>和<span class="math inline">\(j\)</span></li>
</ol>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/%E5%B0%8FQ%E6%88%AA%E5%9B%BE-20150517160709.png" width="400" >
</p>
<p>作者认为这样<strong><em>multi region的<a href="">好处有两个</a>:</em></strong></p>
<ol style="list-style-type: decimal">
<li><a href="">不同的region是focus在不同</a>的物体区域的，所以他们应该是互补的，能够增强特征的多样性</li>
<li>认为这个方法能够有效应对<a href="">object proposal时候定位不准确的问题</a>，并在6.2和6.3通过实验验证</li>
</ol>
<h3 id="sematic-segmentation-aware-cnn"><strong><em>Sematic segmentation-aware CNN</em></strong></h3>
<p>这里的motivation是<a href="">通过segmentation的特征来辅助detection</a>。然后这里训练segmention用的是很出名的<a href="">FCN</a>的流程了，不过这里<a href="">不需要用segmentation的标注</a>，而是用<a href="">bbox</a>就好了，简单粗暴地把bbox里面认为是前景，外面认为是背景即可（也就是如Figure 5的中间一列）。</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/%E5%B0%8FQ%E6%88%AA%E5%9B%BE-20150517151940.png" width="400" >
</p>
<p><strong><em>虽然表面看似这样的标注很粗暴，很多像素都会错标，但是<a href="">CNN的纠错能力是很强的</a></em></strong>，就是将那些标错的pixel都看成是噪声，CNN依然能够根据更多的标对的像素来学习出来一个还不错的模型（如Figure 5的右列）。 用上述的方法训练出来一个<a href="">还不错的segmentation CNN</a>后，<a href="">摘到最后一层，也加到上面的MR-CNN上，进一步增强特征</a>。如Figure 4所示。</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/%E5%B0%8FQ%E6%88%AA%E5%9B%BE-20150517151947.png" width="400" >
</p>
<h3 id="object-localization"><strong><em>Object localization</em></strong></h3>
<p>这一步，对应的是RCNN或者SPP-Net的最后一步，也就是得到结果之后，<a href="">对位置重新进行一次regression</a>，<strong><em>不过这里做了几点的改进</em></strong>：</p>
<ol style="list-style-type: decimal">
<li><a href="">使用CNN来训练regressor</a>（在RCNN中是使用简单的函数来训练regressor的），具体来说跟Fast RCNN比较像啦，输出是4xC个值，其中C是类别个数，不过这里直接用L2 loss拟合完事。</li>
<li><a href="">迭代优化</a>，跟DeepFace比较像，也就是，利用<a href="">分类器打一个分</a>，然后<a href="">筛掉低分</a>的，对于剩下的高分的proposal<a href="">重新回归</a>位置，之后根据这个重新回归的位置再利用分类器打个分，然后再回归一次位置。</li>
<li><a href="">投票机制</a>，上述两步会在<a href="">每个object附近都产生不少bbox</a>，这里利用上附近的bbox进行投票打分，具体来说，取一个最高分的bbox，然后还有它附近跟他<a href="">overlap超过0.5的bbox</a>，然后最后的bbox位置是他们的<a href="">加权平均</a>（权值为overlap）。</li>
</ol>
</body>
</html>
