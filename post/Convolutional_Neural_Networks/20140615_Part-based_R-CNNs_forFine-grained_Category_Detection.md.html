<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h2 id="part-based-r-cnns-forfine-grained-category-detection"><a href="http://arxiv.org/abs/1407.3867">Part-based R-CNNs forFine-grained Category Detection</a></h2>
<p>ECCV14的oral，论文出处：http://www.cs.berkeley.edu/~rbg/papers/part-rcnn.pdf</p>
<h2 id="概述"><strong><em>概述</em></strong></h2>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/小Q截图-20141110155055.png" width="800" >
</p>
<p>fine-grained的核心挑战是<strong><em>定位part</em></strong>，于是这个工作在RCNN上加了part，主体流程见上图：</p>
<ul>
<li>提取<strong><em>region proposal</em></strong>，这里用的selective search</li>
<li>找到<strong><em>物体的bbox</em></strong>和<strong><em>part的bbox</em></strong>，这里需要用到空间信息进行重打分</li>
<li>之后<strong><em>将bbox的特征提取出来</em></strong>，然后分类</li>
</ul>
<h2 id="part-based-rcnns"><strong><em>Part-based RCNNs</em></strong></h2>
<p>训练一个有part的RCNN，满足了两个条件：</p>
<ol style="list-style-type: decimal">
<li>proposal里面<strong><em>覆盖了95%的part</em></strong>;</li>
<li>part<strong><em>有标记信息</em></strong>，可进行<strong><em>有监督学习</em></strong></li>
</ol>
<p>但是其实具体来说，跟RCNN框架还是有点差别的：</p>
<ol style="list-style-type: decimal">
<li>都用ImageNet的模型做pretrain，但这里<strong><em>finetuning一个200的分类器（这里对应了200种鸟）。而RCNN是tuning200类+1背景的</em></strong>。</li>
<li>之后得到<strong><em>特征</em></strong>后，用<strong><em>SVM训练root和part的分类器</em></strong>。RCNN中没有part分类器（而且为啥part的分类器不在CNN中tuning之后再重新训练SVM呢？）</li>
</ol>
<h2 id="geometric-constraints">Geometric constraints</h2>
<p>这里需要对上述root和part进行重新打分，利用到的是part相对于root的空间信息，用式子(1)表示： <span class="math display">\[
\mathbf{X}^*=\text{argmax}_X\Delta (X)\prod_{i=0}^n d_i(x_i) \qquad(1)
\]</span></p>
<p>上面的△(X)表示某种约束。</p>
<p>首先给出第一个约束是part的bbox应该要几乎都在root的bbox里面（最多只有10个像素能在外面），对应式子(2)和(3)：</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/小Q截图-20141110213318.png" width="500" >
</p>
<p>然后给出一个更强的约束是，<strong><em>part相对于root应该是有一个“默认”的位置的（比如鸟头应该在上方等</em></strong>，于是有基于第一个约束有了第二个约束，对应式子(4)： <span class="math display">\[
\Delta _{geometric}(X)=\Delta_{box}(X)(\prod_{i=1}^n\delta_i(x_i))^{\alpha}
\]</span></p>
<p>其中<span class="math inline">\(\delta_i\)</span>代表对part的位置的某种建模方式，文中提到了两种，分别是基于<strong><em>多高斯和最近邻的</em></strong>，对应下面：</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/小Q截图-20141110214248.png" width="500" >
</p>
<p>基于<strong><em>最近邻的定位效果</em></strong>见这个：</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/小Q截图-20141110214356.png" width="500" >
</p>
<h2 id="fine-grained-categorization"><strong><em>Fine-grained categorization</em></strong></h2>
<p>用上述方法得到了root和part的位置后，用CNN提取特征，然后拼成长向量，用SVM求解。</p>
<h2 id="evaluation"><strong><em>Evaluation</em></strong></h2>
<p>用的数据集是Caltech-UCSD bird dataset(CUB200-2011)，有1w+的图片，200类鸟（即平均每类鸟50+张左右），标记有bbox和15个part的位置。 细节：</p>
<ul>
<li>作者只用到了<strong><em>头部和身体这两个part</em></strong>。</li>
<li>CNN特征取的是<strong><em>fc6</em></strong></li>
</ul>
<p>对比结果如下：</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/小Q截图-20141111100054.png" width="500" >
</p>
<p>大致意思是，提升10%以上了。</p>
<p>在给出bbox时候，是state-of-the-art（其中Oracle82%是因为测试阶段也用了bbox还有part标注）。在不给出bbox的时候，因为太难基本没有其他人做，这个方法依然是state-of-the-art。</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/小Q截图-20141111102825.png" width="500" >
</p>
<p>上图给出了<strong><em>去掉part特征时候的结果，也就是只利用空间信息来定位object，依然有提高，说明了空间约束有助于提高结果</em></strong>。</p>
<p align="center">
<img src="http://hexo-pic-zhangliliang.qiniudn.com/小Q截图-20141111103034.png" width="500" >
</p>
<p>上图对应selective search给出的proposal的召回率。在ol&gt;0.5时候，基本都能够召回。在ol&gt;0.7时候，<strong><em>召回率会大幅度下降</em></strong>。所以作者认为<strong><em>目前方法的bottleneck在于proposal方法</em></strong>。</p>
<h2 id="总结"><strong><em>总结</em></strong></h2>
<p>不愧是oral，感觉挺有启发。 提高10%以上主要功劳应该是在CNN特征。 其他贡献是part的定位和几何约束，大概能提高1~2%个点。</p>
</body>
</html>
