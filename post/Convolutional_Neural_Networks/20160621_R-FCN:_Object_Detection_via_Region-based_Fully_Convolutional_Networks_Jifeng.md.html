<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h1 id="r-fcn-object-detection-via-region-based-fully-convolutional-networks"><a href="">R-FCN: Object Detection via Region-based Fully Convolutional Networks</a></h1>
<p>Compared with R-CNN/Faster R-CNN, their region-based detector is fully convolutional with almost all computation shared on the entire image. They apply <strong>position-sensitive score maps</strong> to address a dilemma between <strong>translation-invariance</strong> in image classification and <strong>translation-variance</strong> in object detection.</p>
<h2 id="contributions">CONTRIBUTIONS</h2>
<ol style="list-style-type: decimal">
<li>A framework called Region-based Fully Convolutional Network (R-FCN) is developed for object detection, which consists of shared, fully convolutional architectures.</li>
<li>A set of position-sensitive score maps are introduced to enable FCN representing translation variance.</li>
<li>A unique ROI pooling method is proposed to shepherd information from mentioned score maps.</li>
</ol>
<div class="figure">
<img src="http://joshua881228.webfactional.com/media/uploads/ReadingNote/arXiv_R-FCN/R-FCN.jpg" />

</div>
<h2 id="method">method</h2>
<ol style="list-style-type: decimal">
<li>The image is processed by a FCN manner network.</li>
<li>At the end of FCN, a RPN (Region Proposal Network) is used to generate ROIs.</li>
<li>On the other hand, a score map of <span class="math inline">\(k^2(C+1)\)</span> channels is generated using a bank of specialized convolutional layers.</li>
<li>For each ROI, a selective ROI pooling is utilized to generate a <span class="math inline">\(C+1\)</span> channel score map.</li>
<li>The scores in the score map are averaged to vote for category.</li>
<li>Another <span class="math inline">\(4k^2\)</span> dim convolutional layer is learned for bounding box regression.</li>
</ol>
<p>Position sensitive score maps and RoI pooling: <span class="math display">\[
r_C(i,j|\Theta)=\sum_{(x,y)\in \text{bin}(ij)}z_{i,j,C}(x+x_0,y+y_0|\Theta)/n
\]</span></p>
<h2 id="training-details">Training Details</h2>
<ol style="list-style-type: decimal">
<li>R-FCN is trained end-to-end with pre-computed region proposals. Both category and position are learnt with the loss function: <span class="math inline">\(L(s,t_x,y,w,h)=L_{cls}(s_c^{\ast})+\lambda[c^{\star}&gt;0]L_{reg}(t,t^{\ast})\)</span>. The first loss is classification loss and the second loss is detection loss.</li>
<li>For each image, N proposals are generated and B out of N proposals are selected to train weights according to the highest losses. B is set to 128 in this work.</li>
<li>4-step alternating training is utilized to realizing feature sharing between R-FCN and RPN.</li>
</ol>
<h2 id="advantages">ADVANTAGES</h2>
<ol style="list-style-type: decimal">
<li>It is fast (170ms/image, 2.5-20x faster than Faster R-CNN).</li>
<li>End-to-end training is easier to process.</li>
<li>All learnable layers are convolutional and shared on the entire image, yet encode spatial information required for object detection.</li>
</ol>
<h2 id="disadvantages">DISADVANTAGES</h2>
<p>Compared with Single Shot methods, more computation resource is needed.</p>
</body>
</html>
