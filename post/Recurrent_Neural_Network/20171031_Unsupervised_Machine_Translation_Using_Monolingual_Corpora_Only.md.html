<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h1 id="unsupervised-machine-translation-using-monolingual-corpora-only"><a href="">Unsupervised Machine Translation Using Monolingual Corpora Only</a></h1>
<p>The original mark can be found in this <a href="https://zhuanlan.zhihu.com/p/31404350">blog</a></p>
<blockquote>
<p>现在，使用了深度学习的机器翻译技术往往需要数量非常庞大的平行语料，这一前提使得当前最先进的技术无法被有效地用于那些平行语料比较匮乏的语言之间。</p>
</blockquote>
<p><em><font style="color:red">为了解决这一问题，本文提出了一种不需要任何平行语料的机器翻译模型。该模型的基本思想是, 通过将来自不同语言的句子映射到同一个隐空间下来进行句子翻译。实验证明，在不依靠任何平行语料的情况下，本文所提出模型的BLEU指标达到了32.8</font></em></p>
<h1 id="贡献">　贡献</h1>
<p>相比于（半）监督机器翻译模型，本文所提出的模型具有以下意义：</p>
<h2 id="无需任何监督语料">无需任何监督语料</h2>
<p>仅需要在<font style="color:Red">待翻译的两种语言</font>中存在相应的单语言语料集。这也就意味着该模型可以用于处理那些无标注的新语言之间的翻译问题。</p>
<h2 id="该模型为半监督翻译模型提供了一个性能下界">该模型为半监督翻译模型提供了一个性能下界</h2>
<p>即任何一个（半）监督翻译模型的性能都理应优于本文所提出的模型。</p>
<h1 id="本文所提出模型的基本结构">本文所提出模型的基本结构</h1>
<div class="figure">
<img src="https://pic4.zhimg.com/50/v2-1730db8daf5faa6a7f0d18d470e881b6_hd.jpg" />

</div>
<p>该模型具有以下特点： 1. 首先使用无监督方法获得跨语言的词翻译，然后使用<font style="color:Red">逐词翻译的方法</font>初始化翻译模型； 2. 模型的损失函数可以<font style="color:Red">度量从有噪输入序列中重构句子或翻译句子的能力</font>。 - 对于自编码任务，有噪输入通过丢弃或交换句子中的词获得；Denoising Auto-encoding. 自编码器可以使用seq2seq+attention来实现。然而，如果不加任何限制，自编码器会完全变成一个copy的网络，在这种情况下，模型实际上并没有从数据中学到任何有用的模式。为了解决这一问题，本文使用了类似于Denoising Auto-encoder（去噪自编码器，DAE）的思想：先为输入的句子添加噪声，然后再进行编码 - 对于翻译任务，有噪输入则使用上次迭代获得的翻译结果来表示。为了提高源语言与目标语言句子分布的对齐程度，本文还使用了对抗训练的方法。</p>
</body>
</html>
