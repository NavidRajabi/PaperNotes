<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h2 id="exploring-models-and-data-for-image-question-answering"><a href="http://arxiv.org/abs/1505.02074">Exploring Models and Data for Image Question Answering</a></h2>
<p align="center">
<img src="https://camo.githubusercontent.com/b710800a645c7042c469060fea86567bb7b538bd/687474703a2f2f7333322e706f7374696d672e6f72672f666d396335696a6b352f53637265656e5f53686f745f323031365f30355f30385f61745f365f30325f34335f504d2e706e67" width="500" >
</p>
<ul>
<li><p>Figured out a way to generate training examples infinitely</p></li>
<li><p>Instead of human curated datasets, create questions from image caption</p></li>
<li><p>Parsed the image caption with the Stanford parser, and made them into questions based on hand crafted rules</p></li>
<li><p>Introduces a similar model architecture, except that the input to the LSTM is the CNN embedding</p></li>
<li><p>In section 4.2 and 4.3 introduces many simple baseline net architectures that are referenced in many other papers</p></li>
</ul>
</body>
</html>
