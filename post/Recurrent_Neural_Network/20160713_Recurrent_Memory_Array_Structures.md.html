<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
  </style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h1 id="recurrent-memory-array-structures-code"><a href="http://arxiv.org/abs/1607.03085">Recurrent Memory Array Structures</a>, <a href="https://github.com/krocki/ArrayLSTM">code</a></h1>
<h2 id="basic-lstm">Basic LSTM</h2>
<p><span class="math display">\[
\begin{cases}
f^t=\sigma(W_fx^t+U_fh^{t-1}+b_f)\\
i^t=\sigma(W_ix^t+U_ih^{t-1}+b_i)\\
o^t=\sigma(W_o^t+U_oh^{t-1}+b_o)\\
\hat{c}^{t}=tanh(W_cx^t+U_ch^{t-1}+b_c)\\
c^t=f_t\odot c^{t-1}+i_t\odot \hat{c}^{t}
\end{cases}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua">
<span class="kw">local</span> LSTM <span class="ot">=</span> <span class="ot">{}</span>
<span class="kw">function</span> LSTM<span class="ot">.</span>lstm<span class="ot">(</span>input_size<span class="ot">,</span> rnn_size<span class="ot">,</span> n<span class="ot">,</span> dropout<span class="ot">)</span>
  dropout <span class="ot">=</span> dropout <span class="kw">or</span> <span class="dv">0</span>

  <span class="co">-- there will be 2*n+1 inputs</span>
  <span class="kw">local</span> inputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- x</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_c[L]</span>
    <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_h[L]</span>
  <span class="kw">end</span>

  <span class="kw">local</span> x<span class="ot">,</span> input_size_L
  <span class="kw">local</span> outputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="co">-- c,h from previos timesteps</span>
    <span class="kw">local</span> prev_h <span class="ot">=</span> inputs<span class="ot">[</span>L<span class="ot">*</span><span class="dv">2</span><span class="ot">+</span><span class="dv">1</span><span class="ot">]</span>
    <span class="kw">local</span> prev_c <span class="ot">=</span> inputs<span class="ot">[</span>L<span class="ot">*</span><span class="dv">2</span><span class="ot">]</span>
    <span class="co">-- the input to this layer</span>
    <span class="kw">if</span> L <span class="ot">==</span> <span class="dv">1</span> <span class="kw">then</span>
      x <span class="ot">=</span> OneHot<span class="ot">(</span>input_size<span class="ot">)(</span>inputs<span class="ot">[</span><span class="dv">1</span><span class="ot">])</span>
      input_size_L <span class="ot">=</span> input_size
    <span class="kw">else</span>
      x <span class="ot">=</span> outputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">2</span><span class="ot">]</span>
      <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> x <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>x<span class="ot">)</span> <span class="kw">end</span> <span class="co">-- apply dropout, if any</span>
      input_size_L <span class="ot">=</span> rnn_size
    <span class="kw">end</span>
    <span class="co">-- evaluate the input sums at once for efficiency</span>
    <span class="kw">local</span> i2h <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>input_size_L<span class="ot">,</span> <span class="dv">4</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>x<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;i2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
    <span class="kw">local</span> h2h <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> <span class="dv">4</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>prev_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;h2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
    <span class="kw">local</span> all_input_sums <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>i2h<span class="ot">,</span> h2h<span class="ot">})</span>

    <span class="kw">local</span> reshaped <span class="ot">=</span> nn<span class="ot">.</span>Reshape<span class="ot">(</span><span class="dv">4</span><span class="ot">,</span> rnn_size<span class="ot">)(</span>all_input_sums<span class="ot">)</span>
    <span class="kw">local</span> n1<span class="ot">,</span> n2<span class="ot">,</span> n3<span class="ot">,</span> n4 <span class="ot">=</span> nn<span class="ot">.</span>SplitTable<span class="ot">(</span><span class="dv">2</span><span class="ot">)(</span>reshaped<span class="ot">)</span>:split<span class="ot">(</span><span class="dv">4</span><span class="ot">)</span>
    <span class="co">-- decode the gates</span>
    <span class="kw">local</span> in_gate <span class="ot">=</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n1<span class="ot">)</span>
    <span class="kw">local</span> forget_gate <span class="ot">=</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n2<span class="ot">)</span>
    <span class="kw">local</span> out_gate <span class="ot">=</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n3<span class="ot">)</span>
    <span class="co">-- decode the write inputs</span>
    <span class="kw">local</span> in_transform <span class="ot">=</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>n4<span class="ot">)</span>
    <span class="co">-- perform the LSTM update</span>
    <span class="kw">local</span> next_c           <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>
        nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>forget_gate<span class="ot">,</span> prev_c<span class="ot">}),</span>
        nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>in_gate<span class="ot">,</span>     in_transform<span class="ot">})</span>
      <span class="ot">})</span>
    <span class="co">-- gated cells form the output</span>
    <span class="kw">local</span> next_h <span class="ot">=</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>out_gate<span class="ot">,</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>next_c<span class="ot">)})</span>

    <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_c<span class="ot">)</span>
    <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_h<span class="ot">)</span>
  <span class="kw">end</span>

  <span class="co">-- set up the decoder</span>
  <span class="kw">local</span> top_h <span class="ot">=</span> outputs<span class="ot">[#</span>outputs<span class="ot">]</span>
  <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> top_h <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>top_h<span class="ot">)</span> <span class="kw">end</span>
  <span class="kw">local</span> proj <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> input_size<span class="ot">)(</span>top_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;decoder&#39;</span><span class="ot">}</span>
  <span class="kw">local</span> logsoft <span class="ot">=</span> nn<span class="ot">.</span>LogSoftMax<span class="ot">()(</span>proj<span class="ot">)</span>
  <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> logsoft<span class="ot">)</span>

  <span class="kw">return</span> nn<span class="ot">.</span>gModule<span class="ot">(</span>inputs<span class="ot">,</span> outputs<span class="ot">)</span>
<span class="kw">end</span>

<span class="kw">return</span> LSTM</code></pre></div>
<h2 id="state-sharing-memory-array-lstm">State-sharing Memory: Array-LSTM</h2>
<p><span class="math display">\[
\begin{cases}
f_k^t=\sigma(W_{kf}x^t+U_{kf}h^{t-1}+b_{kf})\\
i_k^t=\sigma(W_{ki}x^t+U_{ki}h^{t-1}+b_{ki})\\
o_k^t=\sigma(W_{ko}^t+U_{ok}h^{t-1}+b_{ko})\\
\hat{c}_k^{t}=tanh(W_{kc}x^t+U_{kc}h^{t-1}+b_{kc})\\
c_k^t=f_k^t\odot c_k^{t-1}+i_k^t\odot \hat{c}_k^{t} \\
h^t=\sum_ko_k^t\odot tanh(c_k^t)
\end{cases}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua"><span class="kw">function</span> ArrayLSTM<span class="ot">.</span>Arraylstm<span class="ot">(</span>input_size<span class="ot">,</span> rnn_size<span class="ot">,</span> n<span class="ot">,</span> dropout<span class="ot">)</span>
  dropout <span class="ot">=</span> dropout <span class="kw">or</span> <span class="dv">0</span>

  <span class="co">-- there will be 5*n+1 inputs</span>
  <span class="kw">local</span> inputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- x</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="kw">for</span> S <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_c_[S][L]. S is from 1 to 4</span>
    <span class="kw">end</span>
    <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_h[L]</span>
  <span class="kw">end</span>

  <span class="kw">local</span> x<span class="ot">,</span> input_size_L
  <span class="kw">local</span> outputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="co">-- c,h from previos timesteps</span>
    <span class="kw">local</span> prev_h   <span class="ot">=</span> inputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">+</span><span class="dv">6</span><span class="ot">]</span>
    <span class="kw">local</span> prev_c <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>prev_c<span class="ot">,</span> inputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">+</span>C<span class="ot">+</span><span class="dv">1</span><span class="ot">])</span>
    <span class="kw">end</span>
    <span class="co">-- the input to this layer</span>
    <span class="kw">if</span> L <span class="ot">==</span> <span class="dv">1</span> <span class="kw">then</span>
      x <span class="ot">=</span> OneHot<span class="ot">(</span>input_size<span class="ot">)(</span>inputs<span class="ot">[</span><span class="dv">1</span><span class="ot">])</span>
      input_size_L <span class="ot">=</span> input_size
    <span class="kw">else</span>
      x <span class="ot">=</span> outputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">]</span>
      <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> x <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>x<span class="ot">)</span> <span class="kw">end</span> <span class="co">-- apply dropout, if any</span>
      input_size_L <span class="ot">=</span> rnn_size
    <span class="kw">end</span>
    <span class="co">-- evaluate the input sums at once for efficiency</span>
    <span class="kw">local</span> next_c <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> next_h <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">for</span> C <span class="ot">=</span><span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="kw">local</span> i2h <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>input_size_L<span class="ot">,</span> <span class="dv">4</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>x<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;i2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
      <span class="kw">local</span> h2h <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> <span class="dv">4</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>prev_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;h2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
      <span class="kw">local</span> all_input_sums <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>i2h<span class="ot">,</span> h2h<span class="ot">})</span>
      <span class="kw">local</span> reshaped <span class="ot">=</span> nn<span class="ot">.</span>Reshape<span class="ot">(</span><span class="dv">4</span><span class="ot">,</span> rnn_size<span class="ot">)(</span>all_input_sums<span class="ot">)</span>
      <span class="kw">local</span> n1<span class="ot">,</span> n2<span class="ot">,</span> n3<span class="ot">,</span> n4 <span class="ot">=</span> nn<span class="ot">.</span>SplitTable<span class="ot">(</span><span class="dv">2</span><span class="ot">)(</span>reshaped<span class="ot">)</span>:split<span class="ot">(</span><span class="dv">4</span><span class="ot">)</span>
      <span class="co">-- decode the gates</span>
      <span class="kw">local</span> in_gate <span class="ot">=</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n1<span class="ot">)</span>
      <span class="kw">local</span> forget_gate <span class="ot">=</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n2<span class="ot">)</span>
      <span class="kw">local</span> out_gate <span class="ot">=</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n3<span class="ot">)</span>
      <span class="co">-- decode the write inputs</span>
      <span class="kw">local</span> in_transform <span class="ot">=</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>n4<span class="ot">)</span>
      <span class="co">-- perform the LSTM update</span>
      <span class="fu">table.insert</span><span class="ot">(</span>next_c<span class="ot">,</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>forget_gate<span class="ot">,</span> prev_c<span class="ot">[</span>C<span class="ot">]}),</span>nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>in_gate<span class="ot">,</span> in_transform<span class="ot">})}))</span>
      <span class="co">-- gated cells form the output</span>
      <span class="fu">table.insert</span><span class="ot">(</span>next_h<span class="ot">,</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>out_gate<span class="ot">,</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>next_c<span class="ot">[</span>C<span class="ot">])}))</span>
    <span class="kw">end</span>
    <span class="kw">local</span> next_h_sum <span class="ot">=</span> next_h<span class="ot">[</span><span class="dv">1</span><span class="ot">]</span>
    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">2</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      next_h_sum <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>next_h_sum<span class="ot">,</span> next_h<span class="ot">[</span>C<span class="ot">]})</span>
    <span class="kw">end</span>

    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_c<span class="ot">[</span>C<span class="ot">])</span>
    <span class="kw">end</span>
    <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_h_sum<span class="ot">)</span>
  <span class="kw">end</span>

  <span class="co">-- set up the decoder</span>
  <span class="kw">local</span> top_h <span class="ot">=</span> outputs<span class="ot">[#</span>outputs<span class="ot">]</span>
  <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> top_h <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>top_h<span class="ot">)</span> <span class="kw">end</span>
  <span class="kw">local</span> proj <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> input_size<span class="ot">)(</span>top_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;decoder&#39;</span><span class="ot">}</span>
  <span class="kw">local</span> logsoft <span class="ot">=</span> nn<span class="ot">.</span>LogSoftMax<span class="ot">()(</span>proj<span class="ot">)</span>
  <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> logsoft<span class="ot">)</span>

  <span class="kw">return</span> nn<span class="ot">.</span>gModule<span class="ot">(</span>inputs<span class="ot">,</span> outputs<span class="ot">)</span>
<span class="kw">end</span></code></pre></div>
<h2 id="deterministic-array-lstm-extensionslane-selection-soft-attention">Deterministic Array-LSTM extensions(Lane selection: Soft attention)</h2>
<p><span class="math display">\[
a_k^t=s_\sigma(W_{ka}x^t+U_{ka}h^{t-1}+b_{ka})\rightarrow s_k^t=\frac{e^{a_k^t}}{\sum_ke^{a_k^t}}\Leftrightarrow
\begin{cases}
f_k^t=s_k^t\odot \sigma(W_{kf}x^t+U_{kf}h^{t-1}+b_{kf})\\
f_k^t=s_k^t\odot \sigma(W_{kf}x^t+U_{kf}h^{t-1}+b_{kf})\\
i_k^t=s_k^t\odot \sigma(W_{ki}x^t+U_{ki}h^{t-1}+b_{ki})\\
o_k^t=s_k^t\odot \sigma(W_{ko}^t+U_{ok}h^{t-1}+b_{ko})\\
\hat{c}_k^{t}=tanh(W_{kc}x^t+U_{kc}h^{t-1}+b_{kc})\\
c_k^t=(1-f_k^t)\odot c_k^{t-1}+i_k^t\odot \hat{c}_k^{t} \\
h^t=\sum_ko_k^t\odot tanh(c_k^t)
\end{cases}
\]</span></p>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua"><span class="kw">function</span> ArrayLSTM<span class="ot">.</span>ArraylstmSoftAtten<span class="ot">(</span>input_size<span class="ot">,</span> rnn_size<span class="ot">,</span> n<span class="ot">,</span> dropout<span class="ot">)</span>
  dropout <span class="ot">=</span> dropout <span class="kw">or</span> <span class="dv">0</span>

  <span class="co">-- there will be 5*n+1 inputs</span>
  <span class="kw">local</span> inputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- x</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="kw">for</span> S <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_c_[S][L]. S is from 1 to 4</span>
    <span class="kw">end</span>
    <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_h[L]</span>
  <span class="kw">end</span>

  <span class="kw">local</span> x<span class="ot">,</span> input_size_L
  <span class="kw">local</span> outputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="co">-- c,h from previos timesteps</span>
    <span class="kw">local</span> prev_h   <span class="ot">=</span> inputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">+</span><span class="dv">6</span><span class="ot">]</span>
    <span class="kw">local</span> prev_c <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>prev_c<span class="ot">,</span> inputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">+</span>C<span class="ot">+</span><span class="dv">1</span><span class="ot">])</span>
    <span class="kw">end</span>
    <span class="co">-- the input to this layer</span>
    <span class="kw">if</span> L <span class="ot">==</span> <span class="dv">1</span> <span class="kw">then</span>
      x <span class="ot">=</span> OneHot<span class="ot">(</span>input_size<span class="ot">)(</span>inputs<span class="ot">[</span><span class="dv">1</span><span class="ot">])</span>
      input_size_L <span class="ot">=</span> input_size
    <span class="kw">else</span>
      x <span class="ot">=</span> outputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">]</span>
      <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> x <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>x<span class="ot">)</span> <span class="kw">end</span> <span class="co">-- apply dropout, if any</span>
      input_size_L <span class="ot">=</span> rnn_size
    <span class="kw">end</span>
    <span class="co">-- evaluate the input sums at once for efficiency</span>
    <span class="kw">local</span> attention <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> n1 <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> n2 <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> n3 <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> n4 <span class="ot">=</span> <span class="ot">{}</span>

    <span class="kw">for</span> C <span class="ot">=</span><span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="kw">local</span> i2h <span class="ot">=</span>  nn<span class="ot">.</span>Linear<span class="ot">(</span>input_size_L<span class="ot">,</span> <span class="dv">5</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>x<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;i2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
      <span class="kw">local</span> h2h <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> <span class="dv">5</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>prev_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;h2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
      <span class="kw">local</span> all_input_sums <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>i2h<span class="ot">,</span> h2h<span class="ot">})</span>
      <span class="kw">local</span> reshaped <span class="ot">=</span> nn<span class="ot">.</span>Reshape<span class="ot">(</span><span class="dv">5</span><span class="ot">,</span> rnn_size<span class="ot">)(</span>all_input_sums<span class="ot">)</span>
      <span class="kw">local</span> n1_tmp<span class="ot">,</span> n2_tmp<span class="ot">,</span> n3_tmp<span class="ot">,</span> n4_tmp<span class="ot">,</span> n5_tmp <span class="ot">=</span> nn<span class="ot">.</span>SplitTable<span class="ot">(</span><span class="dv">2</span><span class="ot">)(</span>reshaped<span class="ot">)</span>:split<span class="ot">(</span><span class="dv">5</span><span class="ot">)</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n1<span class="ot">,</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n1_tmp<span class="ot">))</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n2<span class="ot">,</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n2_tmp<span class="ot">))</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n3<span class="ot">,</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n3_tmp<span class="ot">))</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n4<span class="ot">,</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>n4_tmp<span class="ot">))</span>
      <span class="co">-- attention signals</span>
      <span class="fu">table.insert</span><span class="ot">(</span>attention<span class="ot">,</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n5_tmp<span class="ot">))</span>
    <span class="kw">end</span>

    <span class="kw">local</span> attention_sum <span class="ot">=</span> nn<span class="ot">.</span>Exp<span class="ot">()(</span>attention<span class="ot">[</span><span class="dv">1</span><span class="ot">])</span>
    <span class="kw">for</span> C <span class="ot">=</span><span class="dv">2</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      attention_sum <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>attention_sum<span class="ot">,</span> nn<span class="ot">.</span>Exp<span class="ot">()(</span>attention<span class="ot">[</span>C<span class="ot">])})</span>
    <span class="kw">end</span>

    <span class="kw">local</span> next_c <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> next_h <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">for</span> C <span class="ot">=</span><span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="kw">local</span> attention_norm <span class="ot">=</span> nn<span class="ot">.</span>CDivTable<span class="ot">()({</span>nn<span class="ot">.</span>Exp<span class="ot">()(</span>attention<span class="ot">[</span>C<span class="ot">]),</span> attention_sum<span class="ot">})</span>
      <span class="kw">local</span> in_gate <span class="ot">=</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>n1<span class="ot">[</span>C<span class="ot">],</span>attention_norm<span class="ot">})</span>
      <span class="kw">local</span> forget_gate <span class="ot">=</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>n2<span class="ot">[</span>C<span class="ot">],</span>attention_norm<span class="ot">})</span>
      <span class="kw">local</span> out_gate <span class="ot">=</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>n3<span class="ot">[</span>C<span class="ot">],</span>attention_norm<span class="ot">})</span>
      <span class="kw">local</span> in_transform <span class="ot">=</span> n4<span class="ot">[</span>C<span class="ot">]</span>
      <span class="co">-- perform the LSTM update</span>
      <span class="co">--table.insert(next_c, nn.CAddTable()({nn.CMulTable()({forget_gate, prev_c[C]}),nn.CMulTable()({in_gate, in_transform})}))</span>
      <span class="fu">table.insert</span><span class="ot">(</span>next_c<span class="ot">,</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>nn<span class="ot">.</span>AddConstant<span class="ot">(</span><span class="dv">1</span><span class="ot">,</span><span class="kw">true</span><span class="ot">)(</span>nn<span class="ot">.</span>MulConstant<span class="ot">(-</span><span class="dv">1</span><span class="ot">,</span><span class="kw">true</span><span class="ot">)(</span>forget_gate<span class="ot">)),</span> prev_c<span class="ot">[</span>C<span class="ot">]}),</span>nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>in_gate<span class="ot">,</span> in_transform<span class="ot">})}))</span>
      <span class="co">-- gated cells form the output</span>
      <span class="fu">table.insert</span><span class="ot">(</span>next_h<span class="ot">,</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>out_gate<span class="ot">,</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>next_c<span class="ot">[</span>C<span class="ot">])}))</span>
    <span class="kw">end</span>

    <span class="kw">local</span> next_h_sum <span class="ot">=</span> next_h<span class="ot">[</span><span class="dv">1</span><span class="ot">]</span>
    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">2</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      next_h_sum <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>next_h_sum<span class="ot">,</span> next_h<span class="ot">[</span>C<span class="ot">]})</span>
    <span class="kw">end</span>

    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_c<span class="ot">[</span>C<span class="ot">])</span>
    <span class="kw">end</span>
    <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_h_sum<span class="ot">)</span>
  <span class="kw">end</span>

  <span class="co">-- set up the decoder</span>
  <span class="kw">local</span> top_h <span class="ot">=</span> outputs<span class="ot">[#</span>outputs<span class="ot">]</span>
  <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> top_h <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>top_h<span class="ot">)</span> <span class="kw">end</span>
  <span class="kw">local</span> proj <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> input_size<span class="ot">)(</span>top_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;decoder&#39;</span><span class="ot">}</span>
  <span class="kw">local</span> logsoft <span class="ot">=</span> nn<span class="ot">.</span>LogSoftMax<span class="ot">()(</span>proj<span class="ot">)</span>
  <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> logsoft<span class="ot">)</span>

  <span class="kw">return</span> nn<span class="ot">.</span>gModule<span class="ot">(</span>inputs<span class="ot">,</span> outputs<span class="ot">)</span>
<span class="kw">end</span></code></pre></div>
<h2 id="non-deterministic-array-lstm-extensions">Non-deterministic Array-LSTM extensions</h2>
<h3 id="stochastic-output-pooling">Stochastic Output Pooling</h3>
<div class="sourceCode"><pre class="sourceCode lua"><code class="sourceCode lua"><span class="kw">function</span> ArrayLSTM<span class="ot">.</span>ArraylstmStochasticPooling<span class="ot">(</span>input_size<span class="ot">,</span> rnn_size<span class="ot">,</span> n<span class="ot">,</span> dropout<span class="ot">)</span>
  dropout <span class="ot">=</span> dropout <span class="kw">or</span> <span class="dv">0</span>

  <span class="co">-- there will be 5*n+1 inputs</span>
  <span class="kw">local</span> inputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- x</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="kw">for</span> S <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_c_[S][L]. S is from 1 to 4</span>
    <span class="kw">end</span>
    <span class="fu">table.insert</span><span class="ot">(</span>inputs<span class="ot">,</span> nn<span class="ot">.</span>Identity<span class="ot">()())</span> <span class="co">-- prev_h[L]</span>
  <span class="kw">end</span>

  <span class="kw">local</span> x<span class="ot">,</span> input_size_L
  <span class="kw">local</span> outputs <span class="ot">=</span> <span class="ot">{}</span>
  <span class="kw">for</span> L <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span>n <span class="kw">do</span>
    <span class="co">-- c,h from previos timesteps</span>
    <span class="kw">local</span> prev_h   <span class="ot">=</span> inputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">+</span><span class="dv">6</span><span class="ot">]</span>
    <span class="kw">local</span> prev_c <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>prev_c<span class="ot">,</span> inputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">+</span>C<span class="ot">+</span><span class="dv">1</span><span class="ot">])</span>
    <span class="kw">end</span>
    <span class="co">-- the input to this layer</span>
    <span class="kw">if</span> L <span class="ot">==</span> <span class="dv">1</span> <span class="kw">then</span>
      x <span class="ot">=</span> OneHot<span class="ot">(</span>input_size<span class="ot">)(</span>inputs<span class="ot">[</span><span class="dv">1</span><span class="ot">])</span>
      input_size_L <span class="ot">=</span> input_size
    <span class="kw">else</span>
      x <span class="ot">=</span> outputs<span class="ot">[(</span>L<span class="ot">-</span><span class="dv">1</span><span class="ot">)*</span><span class="dv">5</span><span class="ot">]</span>
      <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> x <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>x<span class="ot">)</span> <span class="kw">end</span> <span class="co">-- apply dropout, if any</span>
      input_size_L <span class="ot">=</span> rnn_size
    <span class="kw">end</span>
    <span class="co">-- evaluate the input sums at once for efficiency</span>
    <span class="kw">local</span> n1 <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> n2 <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> n3 <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> n4 <span class="ot">=</span> <span class="ot">{}</span>

    <span class="kw">for</span> C <span class="ot">=</span><span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="kw">local</span> i2h <span class="ot">=</span>  nn<span class="ot">.</span>Linear<span class="ot">(</span>input_size_L<span class="ot">,</span> <span class="dv">4</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>x<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;i2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
      <span class="kw">local</span> h2h <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> <span class="dv">4</span> <span class="ot">*</span> rnn_size<span class="ot">)(</span>prev_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;h2h_&#39;</span><span class="ot">..</span>L<span class="ot">}</span>
      <span class="kw">local</span> all_input_sums <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>i2h<span class="ot">,</span> h2h<span class="ot">})</span>
      <span class="kw">local</span> reshaped <span class="ot">=</span> nn<span class="ot">.</span>Reshape<span class="ot">(</span><span class="dv">4</span><span class="ot">,</span> rnn_size<span class="ot">)(</span>all_input_sums<span class="ot">)</span>
      <span class="kw">local</span> n1_tmp<span class="ot">,</span> n2_tmp<span class="ot">,</span> n3_tmp<span class="ot">,</span> n4_tmp <span class="ot">=</span> nn<span class="ot">.</span>SplitTable<span class="ot">(</span><span class="dv">2</span><span class="ot">)(</span>reshaped<span class="ot">)</span>:split<span class="ot">(</span><span class="dv">4</span><span class="ot">)</span>
      <span class="co">-- only has 4</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n1<span class="ot">,</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n1_tmp<span class="ot">))</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n2<span class="ot">,</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n2_tmp<span class="ot">))</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n3<span class="ot">,</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>n3_tmp<span class="ot">))</span>
      <span class="fu">table.insert</span><span class="ot">(</span>n4<span class="ot">,</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>n4_tmp<span class="ot">))</span>
    <span class="kw">end</span>

    <span class="kw">local</span> output_gates <span class="ot">=</span> nn<span class="ot">.</span>ConcatTable<span class="ot">()({</span>nn<span class="ot">.</span>ConcatTable<span class="ot">()({</span>n2<span class="ot">[</span><span class="dv">1</span><span class="ot">],</span>n2<span class="ot">[</span><span class="dv">2</span><span class="ot">]}),</span>nn<span class="ot">.</span>ConcatTable<span class="ot">()({</span>n2<span class="ot">[</span><span class="dv">3</span><span class="ot">],</span>n2<span class="ot">[</span><span class="dv">4</span><span class="ot">]})})</span>
    <span class="kw">local</span> output_proj <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span><span class="dv">4</span> <span class="ot">*</span> rnn_size<span class="ot">,</span> <span class="dv">4</span><span class="ot">)(</span>n2<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;stochasticdecoder&#39;</span><span class="ot">}</span>
    <span class="kw">local</span> output_gates_soft <span class="ot">=</span> nn<span class="ot">.</span>Sigmoid<span class="ot">()(</span>nn<span class="ot">.</span>LogSoftMax<span class="ot">()(</span>output_proj<span class="ot">))</span>

    <span class="kw">local</span> next_c <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">local</span> next_h <span class="ot">=</span> <span class="ot">{}</span>
    <span class="kw">for</span> C <span class="ot">=</span><span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="co">-- perform the LSTM update</span>
      <span class="kw">local</span> out_gate <span class="ot">=</span> n2<span class="ot">[</span>C<span class="ot">]</span>
      <span class="kw">local</span> in_gate <span class="ot">=</span> n1<span class="ot">[</span>C<span class="ot">]</span>
      <span class="kw">local</span> forget_gate <span class="ot">=</span>n3<span class="ot">[</span>C<span class="ot">]</span>
      <span class="kw">local</span> in_transform <span class="ot">=</span> n4<span class="ot">[</span>C<span class="ot">]</span>
      <span class="fu">table.insert</span><span class="ot">(</span>next_c<span class="ot">,</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>forget_gate<span class="ot">,</span> prev_c<span class="ot">[</span>C<span class="ot">]}),</span>nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>in_gate<span class="ot">,</span> in_transform<span class="ot">})}))</span>
      <span class="co">-- gated cells form the output</span>
      <span class="fu">table.insert</span><span class="ot">(</span>next_h<span class="ot">,</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>out_gate<span class="ot">,</span> nn<span class="ot">.</span>Tanh<span class="ot">()(</span>next_c<span class="ot">[</span>C<span class="ot">])}))</span>
    <span class="kw">end</span>

    <span class="kw">local</span> next_h_sum <span class="ot">=</span> nn<span class="ot">.</span>CMulTable<span class="ot">()({</span>next_h<span class="ot">[</span><span class="dv">1</span><span class="ot">],</span>output_gates_soft<span class="ot">[</span><span class="dv">1</span><span class="ot">]})</span>
    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">2</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      next_h_sum <span class="ot">=</span> nn<span class="ot">.</span>CAddTable<span class="ot">()({</span>next_h_sum<span class="ot">,</span> nn<span class="ot">.</span>CMul<span class="ot">(</span>output_gates_soft<span class="ot">[</span>C<span class="ot">])(</span>next_h<span class="ot">[</span>C<span class="ot">])})</span>
    <span class="kw">end</span>
    <span class="kw">for</span> C <span class="ot">=</span> <span class="dv">1</span><span class="ot">,</span><span class="dv">4</span> <span class="kw">do</span>
      <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_c<span class="ot">[</span>C<span class="ot">])</span>
    <span class="kw">end</span>
    <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> next_h_sum<span class="ot">)</span>
  <span class="kw">end</span>

  <span class="co">-- set up the decoder</span>
  <span class="kw">local</span> top_h <span class="ot">=</span> outputs<span class="ot">[#</span>outputs<span class="ot">]</span>
  <span class="kw">if</span> dropout <span class="ot">&gt;</span> <span class="dv">0</span> <span class="kw">then</span> top_h <span class="ot">=</span> nn<span class="ot">.</span>Dropout<span class="ot">(</span>dropout<span class="ot">)(</span>top_h<span class="ot">)</span> <span class="kw">end</span>
  <span class="kw">local</span> proj <span class="ot">=</span> nn<span class="ot">.</span>Linear<span class="ot">(</span>rnn_size<span class="ot">,</span> input_size<span class="ot">)(</span>top_h<span class="ot">)</span>:annotate<span class="ot">{</span>name<span class="ot">=</span><span class="st">&#39;decoder&#39;</span><span class="ot">}</span>
  <span class="kw">local</span> logsoft <span class="ot">=</span> nn<span class="ot">.</span>LogSoftMax<span class="ot">()(</span>proj<span class="ot">)</span>
  <span class="fu">table.insert</span><span class="ot">(</span>outputs<span class="ot">,</span> logsoft<span class="ot">)</span>

  <span class="kw">return</span> nn<span class="ot">.</span>gModule<span class="ot">(</span>inputs<span class="ot">,</span> outputs<span class="ot">)</span>
<span class="kw">end</span>

<span class="kw">return</span> ArrayLSTM</code></pre></div>
<h3 id="stochastic-memory-array">Stochastic Memory Array</h3>
</body>
</html>
