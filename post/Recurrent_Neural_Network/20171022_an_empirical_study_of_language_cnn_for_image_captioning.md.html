<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h1 id="自动生成图像描述-an-empirical-study-of-language-cnn-for-image-captioningiccv-2017">自动生成图像描述: An Empirical Study of Language CNN for Image Captioning,ICCV 2017</h1>
<h2 id="论文链接">论文链接</h2>
<p>http://openaccess.thecvf.com/content_iccv_2017/html/Gu_An_Empirical_Study_ICCV_2017_paper.html</p>
<p>简介：我们提出了基于卷积网络CNN的语言模型，该CNN的输入为之前时刻的所有单词，进而可以抓住对生成描述很重要的历史信息，用于指导当前时刻单词的生成。<b>目前，语音建模大多采用LSTM，虽然通过引入“门机制”获得长距离依存性建模的能力。但是LSTM通过逐个单词递推的方式来对语音建模，无论序列长度如何，信息均通过固定长度的向量传递。在输入很长序列，这种逐个递推的方式型很难去学到合理的表达</b>。<font color="red">因此，我们提出的模型贡献在于通过CNN对历史单词进行建模，并结合简单递归模型，解决了长文本层次结构和依存性建模的问题。在MS COCO和Flickr 30K上，该模型性能显著的超过了LSTM和GRU，并均取得了state-of-the-art效果。</font></p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/159893d0d9e5038cf0d109ce249d5e71d5fc0d11/7-Figure3-1.png" />

</div>
<h2 id="导读">导读</h2>
<p>图像描述自动生成是一个融合计算机视觉、自然语言处理和机器学习的综合问题，它类似于翻译一副图片为一段描述文字。该任务不仅需要利用模型去理解图片的内容并且还需要用自然语言去表达它们之间的关系。经过持续数十年计算机视觉、图像识别、自然语言处理和机器学习等领域的发展, 让我们有可能利用神经网络完成突破性的工作.</p>
<p><i>例如, 近年来，ImageNet的兴起,以及大规模图像描述数据库的出现(MS COCO, AI Challenger中文图像), 让研究者们有机会完成更多有实际价值的应用。举个离实际应用比较近的例子, 通过摄像头获取图像或视频，结合图像描述以(Image-to-Text)及语音生成技术(Text-to-Speech)，视障人士可以获得对眼前事物的准确描述。此外，还可能自动对数以千万的未标注图像生成描述以便分类检索.</i></p>
<p>目前，主流的图像描述模型都是基于encoder-decoder结构。其中，encoder为卷积神经网络，同于图像特征抽取。decoder一般为递归神经网络，用于语言模型建模。<font color="red">递归神经网络虽然相对传统方法效果显著。但是，所有递推网络都避免不了一个潜在的问题，那就是当输入序列很长时，历史信息不可避免的会损失。也就是说，虽然门机制一定程度上解决了梯度消失的问题。但是，也带来了缺点。尤其输入序列很长时，由于门机制的存在，递归神经网络难以保留全部的必要信息。</font></p>
<p><b><u>我们提出的基于卷积网络CNN的语言模型则解决了传统encode-decode结构在编解码时都依赖于内部一个固定长度向量的限制</b></u>。该模型主要由四部分组成：用于图像特征提取的CNN_I，用于自然语言建模的CNN_L，融合视觉和文本特征的的多模态层 M，以及单词预测的递归网络。</p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/159893d0d9e5038cf0d109ce249d5e71d5fc0d11/2-Figure1-1.png" />

</div>
<p>描述生成过程过程如下：<b>首先利用CNN提取图像特征，然后CNN_L对历史预测的所有单词进行建模，并得到整体表达。然后，通过多模态层对图像和语音信息进行融合，并将融合的信息输入递归网络预测下一个单词</b>。</p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/159893d0d9e5038cf0d109ce249d5e71d5fc0d11/3-Figure2-1.png" />

</div>
<p>和传统递归神经网络相比，我们的建立了一个输入句子的层级表征，这样可以更好地提取长距离的依存性（long-term dependencies）。这种层次理解的思路和和语言学中语法形式体系中的树结构分析很像。<font color="red">总的来说，我们的模型利用了language CNN天然的整体性理解能力，并结合递归网络的串行理解能力。既获得了长历史信息建模（long-term）的能力，有不丢失时序建模（Short-Term）网络来表达单词信息，进而能够很好的对历史信息建模，用于当前单词的预测</font>。</p>
<p>从我们在MS COCO的对比分析看出,我们的模型很明显的<b>超过了所有的递推神经网络</b>,<font color="red">而且由于引入了language CNN,我们的网络比LSTM网络更容易训练,在Flick30K上,我们超越了目前所有的方法</font>.</p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/159893d0d9e5038cf0d109ce249d5e71d5fc0d11/6-Table5-1.png" />

</div>
</body>
</html>
