<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h1 id="generating-visual-explanations"><a href="http://arxiv.org/pdf/1603.08507.pdf">Generating Visual Explanations</a></h1>
<p>Author's homepage: http://www.eecs.berkeley.edu/~lisa_anne/current_projects.html</p>
<p>They propose a new model that focuses on the <a href="http://dict.youdao.com/w/discriminating/#keyfrom=dict.top">discriminating properties</a> of the visible object, jointly predicts a class label, and explains why the predicted label is appropriate for the image. A loss function based on sampling and reinforcement learning that learns to generate sentences that <strong>realize a global sentence property</strong>, such as <a href="http://dict.youdao.com/w/class%20specificity/#keyfrom=dict.top">class specificity</a>.</p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-03-25/e32dcf5aa3c28e6fbf4da381e03f1bea73e4f1b0/2-Figure2-1.png" />

</div>
<p>Fig.2.Generation of explanatory text with their joint <strong>classification and language model</strong>.</p>
<p><strong>The difference with traditional caption model</strong></p>
<div class="figure">
<img src="https://ai2-s2-public.s3.amazonaws.com/figures/2016-03-25/e32dcf5aa3c28e6fbf4da381e03f1bea73e4f1b0/4-Figure3-1.png" />

</div>
</body>
</html>
