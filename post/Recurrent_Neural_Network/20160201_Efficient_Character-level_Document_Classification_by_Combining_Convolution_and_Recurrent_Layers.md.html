<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h2 id="efficient-character-level-document-classification-by-combining-convolution-and-recurrent-layers"><a href="http://arxiv.org/abs/1602.00367">Efficient Character-level Document Classification by Combining Convolution and Recurrent Layers</a></h2>
<p>TLDR; The authors use a CNN to extract features from character-based document representations. These features are then fed into a RNN to make a final prediction. This model, called ConvRec, has significantly fewer parameters (10-50x) then comparable convolutional models with more layers, but achieves similar to better performance on large-scale document classification tasks.</p>
<h4 id="key-points">Key Points</h4>
<ul>
<li>Shortcomings of word-level approach: Each word is distinct despite common roots, cannot handle OOV words, many parameters.</li>
<li>Character-level Convnets need many layers to capture long-term dependencies due to the small sizes of the receptive fields.</li>
<li>Network architecture: 1. Embedding 8-dim 2. Convnet: 2-5 layers, 5 and 3-dim convolutions, 2-dim pooling, ReLU activation, 3. RNN LSTM with 128d hidden state. Dropout after conv and recurrent layer.</li>
<li>Training: 96 characters, Adadelta, batch size of 128, Examples are padded and masked to longest sequence in batch, gradient norm clipping of 5, early stopping</li>
<li>Models tends to outperform large CNN for smaller datasets. Maybe because of overfitting?</li>
<li>More convolutional layers or more filters doesn't impact model performance much</li>
</ul>
<h4 id="notesquestions">Notes/Questions</h4>
<ul>
<li>Would've been nice to graph the effect of #params on the model performance. How much do additional filters and conv layers help?</li>
<li>hat about training time? How does it compare?</li>
</ul>
</body>
</html>
