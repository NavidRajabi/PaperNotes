<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h2 id="section">2014-2015</h2>
<h3 id="q1">Q1</h3>
<ol style="list-style-type: decimal">
<li><span class="math inline">\((a)\)</span></li>
</ol>
<ol style="list-style-type: decimal">
<li>color space conversion</li>
</ol>
<p>The Y′CBCR color space conversion allows greater compression without a significant effect on perceptual image quality (or greater perceptual image quality for the same compression). The compression is more efficient because the brightness information, which is more important to the eventual perceptual quality of the image, is confined to a single channel. This more closely corresponds to the perception of color in the human visual system. The color transformation also improves compression by statistical decorrelation.</p>
<ol start="2" style="list-style-type: decimal">
<li>down Sampling</li>
</ol>
<p>Due to the densities of color- and brightness-sensitive receptors in the human eye, humans can see considerably more fine detail in the brightness of an image (the Y' component) than in the hue and color saturation of an image (the Cb and Cr components). Using this knowledge, encoders can be designed to compress images more efficiently.</p>
<ol start="3" style="list-style-type: decimal">
<li>forward DCT</li>
</ol>
<p>The advantage of the DCT is its tendency to aggregate most of the signal in one corner of the result, as may be seen above. The quantization step to follow accentuates this effect while simultaneously reducing the overall size of the DCT coefficients, resulting in a signal that is easy to compress efficiently in the entropy stage.</p>
<ol start="4" style="list-style-type: decimal">
<li>quantization</li>
</ol>
<p>The human eye is good at seeing small differences in brightness over a relatively large area, but not so good at distinguishing the exact strength of a high frequency brightness variation. This allows one to greatly reduce the amount of information in the high frequency components. This is done by simply dividing each component in the frequency domain by a constant for that component, and then rounding to the nearest integer.</p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\((b)\)</span></li>
</ol>
<p><span class="math inline">\(X_1=[10,0,1,2,0,1,1,1]\)</span>,<span class="math inline">\(X_2=[3,4,2,0,4,0,2,1]\)</span>,<span class="math inline">\(X_3=[6,1,2,2,2,2,1,0]\)</span> <span class="math inline">\(Dist(X_1,X_2)=sqrt(sum((X_1- X_2) .^ 2))=9.3808\)</span> <span class="math inline">\(Dist(X_1,X_3)=sqrt(sum((X_1- X_3) .^ 2))=4.8990\)</span> <span class="math inline">\(Dist(X_2,X_3)=sqrt(sum((X_2- X_3) .^ 2))=5.6569\)</span></p>
<p>The distance of <span class="math inline">\(X_1,X_3\)</span> is smaller than <span class="math inline">\(X_1,X_2\)</span>, which means <span class="math inline">\(X_1,X_2\)</span> is much similar.</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\((c)\)</span></li>
</ol>
<p><span class="math inline">\(d_{x,b}=\left( \sum_{i=1}^{n}w_i(x_i-b_i)^2)\right)^{1/2}\)</span> where <span class="math inline">\(x_i\)</span> is the value of the i-th measure for the particular data, <span class="math inline">\(b_i\)</span> is the corresponding benchmark value for that measure. <span class="math inline">\(w_i\)</span> is the value of the weight between I will attach to the i-th measure subject to the following: <span class="math inline">\(0&lt;w_i&lt;1\)</span> and <span class="math inline">\(\sum_{i=1}^nw_i=1\)</span>.</p>
<p>Advantages of weighted euclidean distance:</p>
<p>Disadvantages of weighted euclidean distance: This gives the root mean square difference between the means but each squared acousitc parameter difference is first weighted by the variance of that parameter calcuated across all data from all.</p>
<ol start="4" style="list-style-type: decimal">
<li><ol start="4" style="list-style-type: lower-alpha">
<li></li>
</ol></li>
</ol>
<p>Cluster data into 2 groups, As a first step in finding a sensible initial partition, let the A &amp; B values of the two individuals furthest apart (using the Euclidean distance measure), define the initial cluster means, giving:</p>
<p>Group 1, centroid vector (<span class="math inline">\(1,1\)</span>) Group 2, centroid vector (<span class="math inline">\(5,4\)</span>)</p>
<p>The remaining individuals are now examined in sequence and allocated to the cluster to which they are closest, in terms of Euclidean distance to the cluster mean.</p>
<p>Group 1, (1,1);(2,1) Group 2, (4,3);(5,4)</p>
<p>Now the initial partition has changed, and the two clusters at this stage having the following characteristics:</p>
<p>Group 1, centroid vector (1.5,1) Group 2, centroid vector (4.5,3.5)</p>
<p>However, in this example each individual is now nearer its own cluster mean than that of the other cluster and the iteration stops, choosing the latest partitioning as the final cluster solution.</p>
<p>Also, it is possible that the k-means algorithm won't find a final solution. In this case it would be a good idea to consider stopping the algorithm after a pre-chosen maximum of iterations.</p>
<h3 id="q2">Q2</h3>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\((a)\)</span> <span class="math inline">\(|\mathbf{A}-\lambda \mathbf{I}|=8-6\lambda+\lambda^2\rightarrow \lambda_1=2,\lambda_2=4\)</span> <span class="math inline">\(\mathbf{A}.\mathbf{V_1}=\lambda_1.\mathbf{V_1}\rightarrow (\mathbf{A}-\lambda_1).\mathbf{V_1}=0\)</span> <span class="math inline">\(\mathbf{A}.\mathbf{V_2}=\lambda_2.\mathbf{V_2}\rightarrow (\mathbf{A}-\lambda_2).\mathbf{V_2}=0\)</span></p></li>
<li><p><span class="math inline">\((b)\)</span></p></li>
</ol>
<p>SIFT detects and uses a much larger number of features from the images, which reduces the contribution of the errors caused by these local variations in the average error of all feature matching errors.</p>
<p>SIFT keypoints of objects are first extracted from a set of reference images<a href="#section-6">1</a> and stored in a database. An object is recognized in a new image by individually comparing each feature from the new image to this database and finding candidate matching features based on Euclidean distance of their feature vectors. From the full set of matches, subsets of keypoints that agree on the object and its location, scale, and orientation in the new image are identified to filter out good matches. The determination of consistent clusters is performed rapidly by using an efficient hash table implementation of the generalized Hough transform.</p>
<p>Scale-invariant feature detection-&gt;Feature matching and indexing-&gt;Cluster identification by Hough transform voting-&gt;Model verification by linear least squares-&gt;Outlier detection</p>
<ol start="3" style="list-style-type: decimal">
<li><p><span class="math inline">\((c)\)</span> The SIFT features are local and based on the appearance of the object at particular interest points, and are invariant to image scale and rotation. They are also robust to changes in illumination, noise, and minor changes in viewpoint.</p></li>
<li><p><span class="math inline">\((d)\)</span></p></li>
</ol>
<p>feature-based attention, which is attention to specific features such as color, segment orientation, or motion;</p>
<h2 id="q3">Q3</h2>
<ol style="list-style-type: decimal">
<li><span class="math inline">\((a)\)</span> A 2D filter is separable if and only if, viewed as a matrix, it is of rank 1. That is, the rows are all scalar multiples of each other (or, equivalently, the columns are all scalar multiples of each other).</li>
</ol>
<p>Thus, a simple test for separability is to determine the number of linearly independent rows/columns in the 2D filter matrix. If this number is one then the filter is separable.</p>
<p>A more challenging question...</p>
<p>Non-separable filters can often be written as the sum/difference/cascade of filters that are separable.</p>
<p>For example, while the Gaussian filter is separable, the Laplacian of the Gaussian (LOG) is not. (ASIDE: This is one reasons why, for many years, the LOG was approximated as a difference of Gaussians). However, the LOG can be written exactly as the sum of filters, each of which is separable. Last I looked, which was a few years ago, the Matlab image processing toolbox did not take advantage of this fact.</p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\((b)\)</span></li>
</ol>
<ul>
<li>Guassian filtering</li>
<li>Gaussian filtering is a low pass filtering, which means it blurs the signal, attenuating its high frequency components.</li>
<li><span class="math inline">\((256-7)\times (256-7)\)</span></li>
<li>The transformation is the operator that maps a function (signal) to its transform (as with Fourier transformation and Fourier transform, but these two terms are also mixed up frequently). The filter used in the transformation is the filter.</li>
</ul>
<h3 id="q4">Q4</h3>
<h1 id="section-1">2013-2014</h1>
<h2 id="q1-1">Q1</h2>
<ol style="list-style-type: decimal">
<li><ol style="list-style-type: lower-alpha">
<li>Down sampling, Quantization will lose the information.</li>
</ol></li>
<li><ol start="2" style="list-style-type: lower-alpha">
<li><p>First, we calcuate the frequency of each gray scale: <span class="math inline">\(h_1(0)=10/16\)</span> <span class="math inline">\(h_1(1)=0/16\)</span> <span class="math inline">\(h_1(2)=1/16\)</span> <span class="math inline">\(h_1(3)=2/16\)</span> <span class="math inline">\(h_1(4)=0/16\)</span> <span class="math inline">\(h_1(5)=1/16\)</span> <span class="math inline">\(h_1(6)=1/16\)</span> <span class="math inline">\(h_1(7)=1/16\)</span> Second, calcuate their accumlation distribution <span class="math inline">\(r_1(0)=10/16\)</span> <span class="math inline">\(r_1(1)=r_1(0)+h_1(1)=10/16\)</span> <span class="math inline">\(r_1(2)=r_1(1)+h_1(2)=11/16\)</span> <span class="math inline">\(r_1(3)=r_1(2)+h_1(3)=13/16\)</span> <span class="math inline">\(r_1(4)=r_1(3)+h_1(4)=13/16\)</span> <span class="math inline">\(r_1(5)=r_1(4)+h_1(5)=14/16\)</span> <span class="math inline">\(r_1(6)=r_1(5)+h_1(1)=15/16\)</span> <span class="math inline">\(r_1(7)=r_1(6)+h_1(7)=16/16\)</span> Third, quantization <span class="math inline">\(rq_1(0)=ROUND(r_1(0)\times (16-1))=10\)</span> <span class="math inline">\(rq_1(1)=ROUND(r_1(1)\times (16-1))=10\)</span> <span class="math inline">\(rq_1(2)=ROUND(r_1(2)\times (16-1))=11\)</span> <span class="math inline">\(rq_1(3)=ROUND(r_1(3)\times (16-1))=13\)</span> <span class="math inline">\(rq_1(4)=ROUND(r_1(4)\times (16-1))=13\)</span> <span class="math inline">\(rq_1(5)=ROUND(r_1(5)\times (16-1))=14\)</span> <span class="math inline">\(rq_1(6)=ROUND(r_1(6)\times (16-1))=15\)</span> <span class="math inline">\(rq_1(7)=ROUND(r_1(7)\times (16-1))=16\)</span> Finally, the relationship between gray scale and average gray scale:</p>
<pre><code>[10,10,10,10;
 10,11,10,14;
 10,13,10,16;
 13,14,10,10]</code></pre></li>
</ol></li>
</ol>
<p>对颜色特征的表达方式有许多种，我们采用直方图进行特征描述。常见的直方图有两种：统计直方图，累积直方图。我们将分别实验两种直方图在图像聚类和检索中的性能。 - 1. 统计直方图</p>
<p>为利用图像的特征描述图像，可借助特征的统计直方图。图像特征的统计直方图实际是一个1-D的离散函数，即： <span class="math display">\[
H(k)=\frac{n_k}{N},k=0,1,\cdots,L-1
\]</span></p>
<p>上式中k代表图像的特征取值，L是特征可取值个数，<span class="math inline">\(n_k\)</span>是图像中具有特征值为k的像素的个数，N是图像像素的总数，一个示例如下图：其中有8个直方条，对应图像中的8种灰度像素在总像素中的比例。 累计直方图： <img src="http://arthur1200.cnblogs.com/images/cnblogs_com/arthur1200/image006.gif" /> 图像特征统计的累积直方图也是一个1-D的离散函数，即： 上式的各个参数含义同前，与上图对应的累积直方图见下： <span class="math display">\[
I(k)=\sum_{i=0}^k\frac{n_k}{N},k=0,1,\cdots, L-1
\]</span> <img src="http://arthur1200.cnblogs.com/images/cnblogs_com/arthur1200/image010.gif" /> - 2. 直方图相似性度量 得到图像特征的统计直方图后，不同图像之间的特征匹配可借助计算直方图间的相似度量来进行，以下介绍几种常见的直方图的相似度量方法： 另<span class="math inline">\(H_Q(k)\)</span>和<span class="math inline">\(H_D(k)\)</span>分别为两幅图像某一特征的统计直方图，则两图像之间的匹配值<span class="math inline">\(P(Q,D)\)</span>可借助直方图相交来实现，即： <span class="math display">\[
P(Q,D)=\frac{\sum_{k=0}^{L-1}\min [H_Q(k),H_D(k)]}{\sum_{k=0}^{L-1}H_Q(k)}
\]</span> - 3. 直方图匹配法 直方图间的距离可使用一般的欧式距离函数<span class="math inline">\(M_E(Q,D)\)</span>来衡量： <span class="math display">\[
M_E(Q,D)=\sqrt{\sum_{i=1}^L[H_Q(i)-H_D(i)]^2}
\]</span> 我们可以实验多种相似性度量准则，研究它们之间的差异，找出对于某类图像，那种相似性度量能更加准确的描述两幅图像之间的相似程度。</p>
<ol start="3" style="list-style-type: decimal">
<li><p><span class="math inline">\((c)\)</span> mse=mean(mean((x1-x2).<sup>2))=14.9375 mse=mean(mean((x2-x3).</sup>2))=9.1250 mse=mean(mean((x1-x3).^2))=6.3125</p></li>
<li><p><span class="math inline">\((d)\)</span> A:spatial edge distribution B:color histogram C:object shape</p></li>
</ol>
<h2 id="section-2">2</h2>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\((a)\)</span> 关于ＰＣＡ的，略</p></li>
<li><p><span class="math inline">\((b)\)</span> 描述visual attention 的优缺点</p></li>
<li><p><span class="math inline">\((c)\)</span></p></li>
</ol>
<p>https://www.vision.caltech.edu/Image_Datasets/Caltech101/grauman_darrell_iccv05.pdf</p>
<h2 id="section-3">3</h2>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\((a)\)</span> commont on the advantages and Disadvantages of the standard hybrid compression scheme againt standard image compression, for video compression.</p></li>
<li><p><span class="math inline">\((b)\)</span></p></li>
</ol>
<p>IDR帧与I帧的区别: 因为264采用了多帧预测，就有可能在display order下I帧后的P会参考I帧前的帧，这样在random access时如果只找I帧，随后的帧的参考帧可能unvailable，IDR就是这样一种特殊的I帧，把它定义为确保后面的P一定不参考其前面的帧，可以放心地random access。 IDR的出现其实是相当于向解码器发出了一个清理reference buffer的信号吧，上面说前于这一帧的所有已编码帧不能为inter做参考帧了。</p>
<p>I帧和P帧的概念比较好懂，B帧的概念有些模糊，只知道加了B帧图像质量会更好，请问对B帧该怎么理解？ B 帧在 MPEG-4 中有四种参考模式，如果是同时参考前后的画面压缩，则记录的是和 (前画面 pixel 值 + 后画面 pixel 值)/2 的差值，也就是和「前后画面的平均」的差值。所以记录的差值个数和 P 帧一样，只有一个，没有增加。而因为 B 帧位于前后画面的中间，以「前后画面的平均」，也就是「前后画面的中间值」来作为预测数值（预测 B 帧的 pixel 数值为多少？如果有误差，再记录差值），这样这个预测数值会比单独使用前一个画面来预测，更接近目前真正的 B 帧的数值，可想而知，如此所需要记录的差值就会很小甚至可以根本不用记录，所以便可以省下很多的 bits，提高压缩率。 除了压缩率以外，B 帧对画质的影响也是有的，因为 B 帧这种参考前后画面的特性，等于有内插（interpolation）的效果，所以可以减少噪讯。 图像,场,帧 一个视频图像可编码成一个或更多个片，每片包含整数个宏块（MB），即每片至少一个MB，最多时每片包含整个图像的宏块。总之，一幅图像中每片的宏块数不一定固定。 设片的目的是为了限制误码的扩散和传输，应使编码片相互间是独立的。某片的预测不能以其它片中的宏块为参考图像，这样某一片中的预测误差才不会传播到其它片中去。 编码片共有5 种不同类型，除已讲过的I 片、P 片、B 片外，还有SP 片和SI 片。其中SP（切换P）是用于不同编码流之间的切换；它包含P 和/或I 宏块。它是扩展档次中必须具有的切换，它包含了一种特殊类型的编码宏块，叫做SI 宏块，SI 也是扩展档次中的必备功能。 片组是一个编码图象中若干MB 的一个子集，它可包含一个或若干个片。 在一个片组中，每片的MB 按光栅扫描次序被编码，如果每幅图象仅取一个片组，则该图象中所有的MB 均按光栅扫描次序被编码（除非使用ASO，即任意的片次序，即一个编码帧中的片之后可跟随任一解码程序的片）。 还有一种片组，叫灵活宏块次序（FMO），它可用灵活的方法，把编码MB 序列映射到解码图象中MB 的分配用MB 到片组之间的映射来确定，它表示每一个MB 属于哪个片组。表6.2 为MB 到片组的各种映射类型。</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\((c)\)</span> 略</li>
</ol>
<h2 id="section-4">4</h2>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\((a)\)</span></p></li>
<li><p><span class="math inline">\((b)\)</span></p></li>
</ol>
<p><img src="http://images2015.cnblogs.com/blog/310015/201607/310015-20160719153928169-669995876.png" /> 点和线是做图像分析时两个最重要的特征，而线条往往反映了物体的轮廓，对图像中边缘线的检测是图像分割与特征提取的基础。文章主要讨论两个实际工程中常用的边缘检测算法：Sobel边缘检测和Canny边缘检测，Canny边缘检测由于算法复杂将在另一篇文章中单独介绍，文章不涉及太多原理，因为大部分的图像处理书籍都有相关内容介绍，文章主要通过Matlab代码，一步一步具体实现两种经典的边缘检测算法。</p>
<h1 id="section-5">2012-2013</h1>
<h2 id="section-6">1</h2>
<ol style="list-style-type: decimal">
<li><span class="math inline">\((a)\)</span> jpeg 压缩</li>
<li><span class="math inline">\((b)\)</span> 欧式距离</li>
<li><span class="math inline">\(c\)</span> MPEG-7如果改变多媒体annotation和retrieval系统</li>
</ol>
<h2 id="section-7">2</h2>
<ol style="list-style-type: decimal">
<li><span class="math inline">\((a)\)</span> PCA</li>
<li><span class="math inline">\((b)\)</span> SIFT</li>
<li><span class="math inline">\((c)\)</span> pyramid match kernel 作用</li>
</ol>
<h2 id="section-8">3</h2>
<ol style="list-style-type: decimal">
<li><span class="math inline">\((a)\)</span></li>
</ol>
<ul>
<li>bilinear 滤波器 双线型内插值算法就是一种比较好的图像缩放算法，它充分的利用了源图中虚拟点四周的四个真实存在的像素值来共同决定目标图中的一个像素值，因此缩放效果比简单的最邻近插值要好很多。</li>
<li><span class="math inline">\((b)\)</span> <span class="math inline">\(O(n^2)\)</span></li>
<li>证明双线性插值是可分解的</li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\((b)\)</span> 滤波和转换的区别</li>
</ol>
<h2 id="section-9">4</h2>
<p>Motion vector</p>
</body>
</html>
