<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h1 id="media-processing">Media Processing</h1>
<h2 id="数字媒体的存储">数字媒体的存储</h2>
<ol style="list-style-type: decimal">
<li>Image : essentially a sampled two-dimensional space with a intensity value for each position in the 2-D space.</li>
<li>Video : A series of (2-D) image representation of a continuous three-dimensional (3-D) scene (where time is the third dimension).</li>
</ol>
<h2 id="视频-图像">视频 / 图像</h2>
<ol style="list-style-type: decimal">
<li>A Video Image: A projection of a 3-D scene 2-D plane</li>
<li>A 3-D Scene: Consisting of a number of objects each with depth, texture and illumination is projected onto a plane to form a 2-D representation of the scene.</li>
<li>A Still Image: A ‘snapshot’ of the 2-D representation.</li>
</ol>
<h2 id="数字视频">数字视频</h2>
<p>数字视频是一个spatio-temporally（时空）采样的视频场景。每个spatio-temporal采样都表示了图像的光强或亮度。</p>
<h2 id="视频图像获取">视频/图像获取</h2>
<p>Video is captured using a camera or a system of cameras. The camera focuses a 2-D projection of the video scene onto a sensor, such as a charge coupled devices array (CCD array). In the case of color image capture, each color component is filtered and projected onto a separate CCD array.</br> - Stereoscopic(立体的) Representation of Scene. The two images, when viewed in the left and right eye of the viewer, give an appearance of ‘depth’ to the scene. There is an increasing interest in the use of 3-D digital video. - Multi-View Cameras &amp; Display System.</p>
<h2 id="图像显示">图像显示</h2>
<p>The most common type of display is the cathode ray tube (CRT). Liquid crystal displays (LCDs) Flat-panel plasma displays. Becoming popular, brightness improving, cost is high. Have a limited lifespan.</p>
<h2 id="颜色空间">颜色空间</h2>
<p>輻射能频谱（radiant energy spectrum）包含了：audio frequencies, radio frequencies, infrared, visible light, ultraviolet rays, x-rays, and gamma rays. - A monochrome (‘grey scale’) video image may be represented using just one number per spatio- temporal sample. - Two of the most common color spaces for digital image and video representation： RGB (Red-Green-Blue)； YCrCb (Luminance/Color Chrominance) - Color Space - RGB. Each pixel is represented by three numbers indicating the relative proportions of Red, Green and Blue. These are the three additive primary colors of light. Any visible color may be reproduced by combining varying proportions of Red, Green and Blue light. - Using 8 bits per component is quite common: 3 x 8 = 24 bits are required to represent each pixel. (True Color)</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(YC_rC_b\)</span> RGB is not necessarily the most efficient representation of color. The human visual system (HVS) is less sensitive to color than to luminance. A popular color space of this type is <span class="math inline">\(Y: C_r : C_b\)</span>. <span class="math inline">\(Y=k_rR+k_gG+k_bB\)</span>, Y is the luminance component, k are weighting factors.</br> Each chrominance component is the difference between R, G or B and the luminance Y:<span class="math inline">\(\begin{cases}C_r=R-y\\C_b=B-Y\\C_g=G-Y\end{cases}\)</span>. <span class="math inline">\(C_r+C_b+C_g\)</span> is a constant</br> Only two of the three chrominance components need to be transmitted</br> In the <span class="math inline">\(Y\)</span> : <span class="math inline">\(C_r\)</span> : <span class="math inline">\(C_b\)</span> space, only the luminance (Y) and red and blue chrominance (<span class="math inline">\(C_r\)</span>, <span class="math inline">\(C_b\)</span>) are transmitted.</br>
<ul>
<li>The key advantage ofY:Cr :Cb over RGB is that the Cr and Cb components may be represented with a lower resolution than Y because the HVS is less sensitive to color than luminance.</li>
<li>4 : 4 : 4 means that the three components (Y: Cr : Cb) have the same resolution and hence a sample of each component exists at every pixel position.</li>
<li>4 : 2 : 2 means that the chrominance components have the same vertical resolution but half the horizontal resolution.</li>
<li>4 : 2 : 0 means that Cr and Cb each have half the horizontal and vertical resolution of Y.</li>
</ul></li>
<li>HVS – Human Eyes The main components of the HVS:</li>
</ol>
<ul>
<li>Eye: The image is focused by the lens onto the photo detecting area of the eye.</li>
<li>Retina: The retina consists of an array of cones (photoreceptors sensitive to colour at high light levels) and rods (photoreceptors sensitive to luminance at low light levels).</li>
<li>The more sensitive cones are concentrated in a central region (the fovea) which means that high-resolution colour vision is only achieved over a small area at the centre of the field of view.</li>
<li>Optic nerve</li>
<li>Brain</li>
<li>HVS - Retina</li>
<li>Consists of Cones and Rods:</li>
<li>Cones: color receptors; About 7 million, primarily in the retina’s central portion; for image details</li>
<li>Rods: Sensitive to illumination, not involved in color vision ; About 130 million, all over the retina; General, overall view</li>
</ul>
<h1 id="transform-coding">Transform Coding</h1>
<p>Transform coding is at the heart of the majority of video coding systems and standards. Spatial image data is inherently ‘difficult’ to compress:neighboring samples are highly correlated (interrelated) and the energy tends to be evenly distributed across an image, making it difficult to discard data or reduce the precision of data without adversely affecting image quality.</p>
<p>With a suitable transformation, the data is ‘easier’ to compress in the transform domain. There are several desirable properties of a transform for compression. - compact the energy in the image - De-correlate the data - suitable for practical implementation in software and hardware</p>
<p>The two most widely used image compression transforms: 1. discrete cosine trans-form (DCT).usually applied to small, regular blocks of image samples (e.g. 8 x 8 squares) 2. discrete wavelet transform (DWT). usually applied to larger image sections (‘tiles’) or to complete images.</p>
<p>The DCT has proved particularly durable and is at the core of most of the current generation of image and video coding standards. including JPEG, H.261, H.263, H.263+, MPEG-1, MPEG-2 and MPEG-4.</p>
<p>The DWT is gaining popularity because it can outperform the DCT for still image coding. new JPEG image coding standard (JPEG-2000) and for still ‘texture’ coding in MPEG-4.</p>
<h2 id="离散余弦变换dct-discrete-cosine-transform">离散余弦变换（DCT-Discrete Cosine Transform）</h2>
<p>MPEG采用了Ahmed（一个巨牛的数学家） 等人于70年代提出的离散余弦变换（DCT-Discrete Cosine Transform）压缩算法，降低视频信号的空间冗余度。</p>
<p>DCT将运动补偿误差或原画面信息块转换成代表不同频率分量的系数集，这有两个优点： 1. 信号常将其能量的大部分集中于频率域的1个小范围内，这样一来，描述不重要的分量只需要很少的比特数 2. 频率域分解映射了人类视觉系统的处理过程，并允许后继的 量化过程满足其灵敏度的要求</p>
<pre><code>视频信号的频谱线在0-6MHz范围内，而且1幅视频图像内包含的大多数为低频频谱线，只在占图像区域比例很低的图像边缘的视频信号中才含有高频的谱线。因此，在视频信号数字处理时，可根据频谱因素分配比特数：对包含信息量大的低频谱区域分配较多的比特数，对包含信息量低的高频 谱区域分配较少的比特数，而图像质量并没有可察觉的损伤，达到码率压缩的目的。然而，这一切要在低熵(Entropy)值的情况下，才能达到有效的编码。能否对一串数据进行有效的编码，取决于每个数据出现的概率。每个数据出现的概率差别大，就表明熵值低， 可以对该串数据进行高效编码。反之，出现的概率差别小，熵值高，则不能进行高效编码。视频信号的数字化是在规定的取样频率下由A/D转换器对视频电平转换而来的，每个像素的视频信号幅度随着每层的时间而周期性地变化。每个像素的平均信息量的总和为总平均信息量，即熵值。由于每个视频电平发生几乎具有相等的概率，所以视频信号的熵值很高。 熵值是一个定义码率压缩率的参数，视频图像的压缩率依赖于视频信号的熵值，在多数情况下视频信号为高熵值，要进行高效编码，就要将高熵值变为低熵值。怎样变成低熵值呢？这就需要分析视频频谱的特点。大多数情况下，视频频谱的幅度随着频率的升高而降低。其中 低频频谱在几乎相等的概率下获得0到最高的电平。与此相对照，高频频谱通常得到的是低电平及稀少的高电平。显然，低频频谱具有较高的熵值，高频频谱具有较低的熵值。据此，可对视频的低频分量和高频分量分别处理，获得高频的压缩值。</code></pre>
<p>由上面的引用可见，码率压缩基于变换编码和熵值编码两种算法。前者用于降低熵值，后者将数据变为可降低比特数的有效编码方式。</p>
<p>在MPEG标准中，变换编码采用的是DCT，变换过程本身虽然并不产生码率压缩作用，但是变换后的频率系数却非常有利于码率压缩。 实际上压缩数字视频信号的整个过程分为块取样、DCT、量化、编码4个主要过程进行-----首先在时间域将原始图像分成N(水平)×N（垂直）取样块，根据需要可选择4×4、4×8、8×8、8×16、16×16等块，这些取样的像素块代表了原图像帧各像素的灰度值，其范围在139-163之间，并依序送入DCT编码器，以便将取样块由时间域转换为频率域的DCT系数块。DCT系统的转换分别在每个取样块中进行，这些块中每个取样是数字化后的值，表示一场中对应像素的视频信号幅度值。</p>
<p><strong>DCT和它解压时的反运算的具体算法如下</strong>: 一个<span class="math inline">\(8\times 8\)</span>的前向DCT： <span class="math display">\[
F_{x,y}=\frac{C(x)C(y)}{4}\sum_{i=0}^7\sum_{j=0}^7 f_{i,j}\cos (\frac{(2i+1)x\pi}{16})\cos(\frac{(2j+1)y\pi}{16})
\]</span></p>
<h1 id="离散小波变换discrete-wavelet-transform">离散小波变换/Discrete Wavelet Transform</h1>
<p>离散小波变换（Discrete Wavelet Transform）在数值分析和时频分析中很有用。第一个离散小波变换由匈牙利数学家发明，离散小波变换顾名思义就是离散的输入以及离散的输出，但是这里并没有一个简单而明确的公式来表示输入及输出的关系，只能以阶层式架构来表示。</p>
<p>首先我们定义一些需要用到的信号及滤波器。 - <span class="math inline">\(x[n]\)</span>：离散的输入信号，长度为N。 - <span class="math inline">\(g[n]\)</span>：low pass filter低通滤波器，可以将输入信号的高频部份滤掉而输出低频部份。 - <span class="math inline">\(h[n]\)</span>：high pass filter高通滤波器，与低通滤波器相反，滤掉低频部份而输出高频部份。 - <span class="math inline">\(\downarrow Q\)</span>：downsampling filter降采样滤波器，如果以<span class="math inline">\(x[n]\)</span>作为输入，则输出<span class="math inline">\(y[n]=x[Qn]\)</span>。此处举例Q=2。</p>
<div class="figure">
<img src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/DiscreteWaveletTrans1.jpg/400px-DiscreteWaveletTrans1.jpg" />

</div>
<p>清楚规定以上符号之后，便可以利用阶层架构来介绍如何将一个离散信号作离散小波变换：</p>
<div class="figure">
<img src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/DWT2ndLayer.jpg/500px-DWT2ndLayer.jpg" />

</div>
<p>架构中的第1层(1st stage) <span class="math inline">\(\begin{cases}x_{1,L}[n]=\sum_{k=0}^{K-1} x[2n-k]g[k] \\ x_{1,H}[n]=\sum_{k=0}^{K-1} x[2n-k]h[k] \end{cases}\)</span> 架构中的第2层(2nd stage) <span class="math inline">\(\begin{cases} x_{2,L}[n]=\sum_{k=0}^{K-1} x_{1,L}[2n-k]g[k] \\  x_{2,H}[n]=\sum_{k=0}^{K-1} x_{1,L}[2n-k]h[k] \end{cases}\)</span></p>
<p>可继续延伸: <img src="http://upload.wikimedia.org/wikipedia/commons/2/22/Wavelets_-_Filter_Bank.png" /></p>
<p>架构中的第α层(α ? th stage)<span class="math inline">\(\begin{cases} x_{\alpha ,L}[n]=\sum_{k=0}^{K-1} x_{\alpha -1,L}[2n-k]g[k] \\ x_{\alpha ,H}[n]=\sum_{k=0}^{K-1} x_{\alpha -1,L}[2n-k]h[k] \end{cases}\)</span></p>
<p>注意：若输入信号<span class="math inline">\(x[n]\)</span>的长度是N，则第α层中的<span class="math inline">\(x_{\alpha,L}[n]\)</span>及<span class="math inline">\(x_{\alpha}\)</span>,<span class="math inline">\(H[n]\)</span>的长度为 <span class="math inline">\(\frac{N}{2^\alpha }\)</span></p>
<p><strong>2-D Discrete Wavelet Transform</strong> <img src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/2D_DWT.jpg/500px-2D_DWT.jpg" /></p>
<p>此时的输入信号变成x[m,n]，而转换过程变得更复杂，说明如下： 1. 首先对n方向作高通、低通以及降频的处理: <span class="math display">\[
    \begin{cases}
    v_{1,L}[m,n]=\sum_{k=0}^{K-1} x[m,2n-k]g[k] \\
    v_{1,H}[m,n]=\sum_{k=0}^{K-1} x[m,2n-k]h[k]
    \end{cases}
    \]</span> 2. 接着对<span class="math inline">\(v_{1,L}[m,n]\)</span>与<span class="math inline">\(v_{1,H}[m,n]\)</span>延著m方向作高低通及降频动作 <span class="math display">\[
    \begin{cases}
    x_{1,LL}[m,n]=\sum_{k=0}^{K-1} v_{1,L}[2m-k,n]g[k] \\
    x_{1,HL}[m,n]=\sum_{k=0}^{K-1} v_{1,L}[2m-k,n]h[k] \\
    x_{1,LH}[m,n]=\sum_{k=0}^{K-1} v_{1,H}[2m-k,n]g[k] \\
    x_{1,HH}[m,n]=\sum_{k=0}^{K-1} v_{1,H}[2m-k,n]h[k]
    \end{cases}
    \]</span></br> 经过(1)(2)两个步骤才算完成2-D DWT的一个stage。</p>
<p><strong>实际范例</strong> 以下根据上述2-D DWT的步骤，对一张影像作二维离散小波变换(2D Discrete Wavelet Transform) 1. 原始影像 <img src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/2D_DWT_Original.png/300px-2D_DWT_Original.png" /> 2. 2D DWT的结果 <img src="http://upload.wikimedia.org/wikipedia/commons/1/1f/2D_DWT_pre-process.png" /> <img src="http://upload.wikimedia.org/wikipedia/commons/b/ba/2D_DWT_process.png" /></p>
<h1 id="important-properties-of-wavelet-decomposition">Important properties of wavelet decomposition</h1>
<ul>
<li>The number of wavelet ‘coefficients’ is the same as the number of pixels in the original image and so the transform is not inherently adding or removing information.</li>
<li>Many of the coefficients of the high-frequency components (‘HH’, ‘HL‘ and ‘LH’ at each stage) are zero or insignificant.
<ul>
<li>Compression is achieved if we discard the insignificant higher-frequency coefficients whilst preserving the significant ones.</li>
</ul></li>
<li>The decomposition is not restricted by block boundaries (unlike the DCT) and hence may be a more flexible way of de-correlating the image data than the block-based DCT.</li>
</ul>
<h2 id="零树编码zero-tree-coding">零树编码/Zero-tree coding</h2>
<p>信号的传输和处理少不了编码技术的支持，信号编码可以极大地压缩信息量，增强抗干扰能力等。同样地，小波变换作为一种信号处理技术，也有其独特的编码结构。在《基于小波变换的图像压缩技术初探》一文中，我们提到，二维小波变换具有塔式结构.</p>
<p>那么这种塔式结构里，小波系数和相应的位置信息的组织关系是怎样的呢？仔细观察图1，我们可以发现，各个子图像（或称子频带）之间组成了一个从低频带指向高频带的树状结构，如图2所示：</p>
<div class="figure">
<img src="http://p.blog.csdn.net/images/p_blog_csdn_net/chenyusiyuan/348003/o_EZW03.JPG" />

</div>
<p>图2中，以HH3单个元素为根形成的子孙树，从它们的方向和空间位置可以看出，这种小波树中，各级分解子带的系数之间存在很大的相似性！基于这一性质，Lewis和Knowles在1992年提出了小波零树编码算法。这种算法的一大特点，也是一大缺点，即量化后系数为0的系数的子孙系数也置0。这种一刀切的处理很容易把重要的子孙系数忽略掉，故L-K零树编码算法存在一定的不足。</p>
<p>如果一个小波系数被量化为0，而它存在一个子孙量化后不为0，则这个点称为孤立零点。适应孤立零点的情况而改进的零树编码算法就称为嵌入式零树小波编码算法，简称EZW算法，是Shapiro在1993年提出的。</p>
<p>对于一个阈值T，若小波系数x满足 |x| &gt;= T ，则称x关于T是重要的系数，反之称x关于T是不重要的系数；若x是不重要的系数，并且其所有子孙都是不重要的，则称x是关于T的零树根；若x本身是不重要的系数，但它存在重要的子孙，则称x是关于T的孤立零点。</p>
<p>对于给定的阈值，EZW算法下图所示的Z型顺序扫描、处理小波系数（扫描顺序有两种：raster、Morton）。</p>
<div class="figure">
<img src="http://p.blog.csdn.net/images/p_blog_csdn_net/chenyusiyuan/348003/o_EZW04.JPG" />

</div>
<p>EZW算法根据小波分解的级数对编码图像进行扫描，扫描次数可按精度要求任意确定，与小波分解级数无关。每次扫描的处理步骤如下：</p>
<div class="figure">
<img src="http://p.blog.csdn.net/images/p_blog_csdn_net/chenyusiyuan/348003/o_EZW05.JPG" />

</div>
<p>（2）主扫描 本文中扫描次序采用图1所示的Morton次序，第i次扫描（i=1,2,…,L）时，算法按此顺序将小波分解系数与阈值Ti-1进行比较，已处理的元素由以下输出符号来表示： P：正的重要元素 N：负的重要元素 T：零树根 Z：孤立零点</p>
<div class="figure">
<img src="http://p.blog.csdn.net/images/p_blog_csdn_net/chenyusiyuan/348003/o_EZW06.JPG" />

</div>
<p>在扫描过程中，用一个主扫描表记录这些输出符号。第i次扫描结束后，将输出符号为P或N的系数的位置加标记、或将这些系数置0，以免下次主扫描重复编码。</p>
<p>（3）辅扫描 辅扫描对主扫描表进行顺序扫描，对其中输出符号为P或N的小波系数进行量化。在量化系数之前要构造量化器。量化器的输入间隔为[ <span class="math inline">\(T_{i-1}\)</span>，2 <span class="math inline">\(T_{i-1}\)</span> ），将其等分为两个量化区间[ <span class="math inline">\(T_{i-1}\)</span>，1.5 <span class="math inline">\(T_{i-1}\)</span> ），[1.5<span class="math inline">\(T_{i-1}\)</span>，2 <span class="math inline">\(T_{i-1}\)</span> ），若小波系数属于前一区间，则输出量化符号“0”，重构值为1.25 Ti-1，否则输出量化符号为“1”，重构值为1.75 <span class="math inline">\(T_{i-1}\)</span>。输出的符号“0”、“1”由一个辅扫描表记录。</p>
<p>（4）重新排序（实际上，重新排序对图像重构影响不大，一般可省略这一步骤） 为便于设置第i+1次扫描所用的量化间隔，以提高解码精度，对输出符号为P或N的数据重新排序。即将幅值在[1.5<span class="math inline">\(T_{i-1}\)</span>，2 <span class="math inline">\(T_{i-1}\)</span> ）中的数据排在幅值位于[ <span class="math inline">\(T_{i-1}\)</span>，1.5 <span class="math inline">\(T_{i-1}\)</span> ）中的数据之前。</p>
<p>（5）输出编码信号 编码器的输出信息有两类：一是给解码器的信息，包括阈值、主扫描表和辅扫描表；二是用于下次扫描的信息，包括阈值、重新排序后的重要系数序列。</p>
</body>
</html>
