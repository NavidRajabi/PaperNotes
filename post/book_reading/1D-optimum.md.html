<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h2 id="最优化方法总结">最优化方法总结</h2>
<p>最优化和方程求根类似，但是方程求根是找<strong><em>零点</em></strong>,而最优化则是找<strong><em>最大值或最小值</em></strong>.</p>
<p>最优化问题的一些典型例子： 售货员在各个城市之间的最短路径； 最优计划和行程安排 误差最小的统计分析和模型.</p>
<ol style="list-style-type: decimal">
<li>一维无约束最优化</li>
</ol>
<p>这类问题可以简单的描述为求解单变量函数<span class="math inline">\(f(x)\)</span>最大值<span class="math inline">\(\text{max}f(x)\)</span>和最小值<span class="math inline">\(\text{min}f(x)\)</span>的问题．</p>
<p align="center">
<img src="http://www.52nlp.cn/images/opt1-1.png" width="250" >
</p>
<ol start="2" style="list-style-type: decimal">
<li>黄金分割搜索法</li>
</ol>
<p>在用黄金分割搜索算法时，首先需要假定一个区间（该区间包含一个答案）． 和<strong><em>二分搜索法</em></strong>不同的是，黄金搜索需要３个函数值来确定是否存在最大值，而第三个值的选取则是通过<strong><em>黄金比例</em></strong>来选择．</p>
<p><strong>内点选择标准：</strong> <span class="math inline">\(\begin{cases}x_1=x_l+d \\ x_2=x_u-d\end{cases}\)</span>, <span class="math inline">\(d=\frac{\sqrt{5}-1}{2}(x_u-x_l)\)</span></p>
<p><span class="math inline">\(\Rightarrow f(x_2)&gt;f(x_1)\)</span>, 排除<span class="math inline">\(x_l \leftrightarrow x_2\)</span> 区间，得到新的<span class="math inline">\(x_l=x_2\)</span>; <em>同时</em>，旧的<span class="math inline">\(x_1\)</span>成为新的<span class="math inline">\(x_2\)</span>, 新的<span class="math inline">\(x_1=x_l+\frac{\sqrt{5}-1}{2}(x_u-x_l)\)</span>, ... <span class="math inline">\(\Rightarrow f(x_1)&gt;f(x_2)\)</span>, 排除<span class="math inline">\(x_1 \leftrightarrow x_u\)</span> 区间，得到新的<span class="math inline">\(x_u=x_1\)</span>; <em>同时</em>，旧的<span class="math inline">\(x_2\)</span>成为新的<span class="math inline">\(x_1\)</span>, 新的<span class="math inline">\(x_2=x_u-\frac{\sqrt{5}-1}{2}(x_u-x_l)\)</span>, ...</p>
<p><em>上面<span class="math inline">\(d\)</span>的推导过程为</em>：给定<span class="math inline">\(x_l,x_u\)</span>之间２段分段<span class="math inline">\(l_1,l_2\)</span>. 使得满足　<span class="math inline">\(\frac{l_1}{l_1+l_2}=\frac{l_2}{l_1} \Rightarrow \frac{l_2}{l_1}=\frac{\sqrt{5}-1}{2}\)</span>　</p>
<p><span style="color:red"><strong><em>优点</em></strong></span>：　减少了单个函数的计算量 <span style="color:red"><strong><em>缺点</em></strong></span>：　黄金分割算法依赖于单个最优点的初始值估计（也就是假定一个包含答案的区间); 同时，黄金分割算法在某些情况下需要大量计算．</p>
<p>（２）二次插值法</p>
<p>二次插值法利用二次多项式可以在最优点附近较好的逼近函数<span class="math inline">\(f(x)\)</span>的形状这一特性． 给定３个点<span class="math inline">\(\{x_0,x_1,x_2\}\)</span>，可以决定一个二次多项式，并得到这个多项式最优解 <span class="math inline">\(x_3=\frac{f(x_0)^2(x_1^2-x_2^2)+f(x_1)(x_2^2-x_0^2)+f(x_2)(x_0^2-x_1^2)}{2f(x_0)(x_1-x_2)+2f(x_1)(x_2-x_0)+2f(x_2)(x_0-x_1)}\)</span></p>
<p>得到这个解后可以利用正割法（类似黄金分割搜索法）选取最新的区间<span class="math inline">\(\{x_0&#39;,x_1&#39;x_2&#39;\}\)</span>, 然后再次计算．</p>
<p align="center">
<img src="../images/posts/2016-04-16/quadratric_optimize.png" width="200" >
</p>
<p><span style="color:red"><strong><em>优点</em></strong></span>：　确定<span class="math inline">\(x_3\)</span>是利用二次函数极值，所以更接近最优解，因此二次插值可望收敛较快． <span style="color:red"><strong><em>缺点</em></strong></span>：　收敛速度比黄金分割法快，但可靠性不如黄金分割法好，程序也较长</p>
<p>（３）牛顿法</p>
<p align="center">
<img src="../images/posts/2016-04-16/newton_repson.png" width="200" >
</p>
<p>牛顿－锐普逊是一种开方法，可以求出<span class="math inline">\(f(x)=0\)</span>的函数根<span class="math inline">\(x\)</span>, 此方法总结为：<span class="math inline">\(x_{i_1}=x_i-\frac{f(x_i)}{f&#39;(x_i)}\)</span> 同理，我们可以借助于这个思想：定义一个新的函数<span class="math inline">\(g(x)=f&#39;(x)\)</span>, 由于最优值<span class="math inline">\(x^*\)</span>同时满足<span class="math inline">\(f&#39;(x^*)=g(x^*)=0\)</span>. 则可以用<span class="math inline">\(x_{i+1}=x_i-\frac{f&#39;(x_i)}{f&#39;&#39;(x_i)}\)</span>作为找<span class="math inline">\(f(x)\)</span>最大值或最小值的方法．</p>
<p><span style="color:red"><strong><em>优点</em></strong></span>： 不需要界定最优值的初始估计值． <span style="color:red"><strong><em>缺点</em></strong></span>：　收敛速度快，但不稳定（有可能发散，牛顿－锐普逊的缺点），计算也较困难</p>
<ol start="2" style="list-style-type: decimal">
<li>多维无约束最优化</li>
</ol>
<p>形象的理解，二维约束优化就是找三维地形图中山峰或河谷．</p>
<p>（１）不计算导数</p>
<p>如果懒得计算导数的话，比较直接的就是强行随机搜索，只要次数足够多，肯定找得到．这种方法最不连续和不可微函数都有效，而且一般找到的都是全局最优解，而非局部最优解．缺点也很明显，计算代价太大．</p>
<p>有更复杂的算法，这些一般都是<strong><em>启发式</em></strong>算法：模拟退火，禁忌搜索，人工神经网络，遗传算法．</p>
<p>单变量检索相对随机搜索好处是每次之改变一个变量的值来改进近似值．由于只有一个值，那么这个问题就简化为一维函数，求解方法很多．<strong><em>Powell方法</em></strong>是基于观测的思想，沿着共轭方向进行搜索，并且当接近真值时，是二次收敛的．</p>
<p><strong><em>共轭方向(conjugate direction)</em></strong>：若点１和２通过在方向相同但起始点不同的一维检索获得，那么由点１和点２构成的直线将直接指向最大值．</p>
<p>（２）计算导数</p>
<p>梯度法明确利用导数信息来求最优值．梯度的计算公式为:<span class="math inline">\(\triangledown f=\frac{\partial f}{\partial x}i+\frac{\partial f}{\partial y}j\)</span>, 如果把当前位置定义为这个轴的原点，那么在这个方向上的斜率定义为<span class="math inline">\(g&#39;(0)=\frac{\partial f}{\partial x}cos \theta+\frac{\partial f}{\partial y}sin \theta\)</span>.</p>
<blockquote>
<p>例子</p>
</blockquote>
<p>计算<span class="math inline">\(f(x,y)=xy^2\)</span> 在(2,2)的最陡上升方向．</p>
<p><span class="math inline">\(\begin{cases}\frac{\partial f}{\partial x}=y^2=4 \\ \frac{\partial f}{\partial y}=2xy=8\end{cases} \Rightarrow \triangledown \begin{cases}f=4i+8j \\ \theta =tan^{-1}(8/4) \\ |\triangledown f|=\sqrt{4^4+8^2}\end{cases}\)</span></p>
<p>虽然我们在起始点获得最大斜率，但是山脊不是直线，前进的路径会随着我们移动渐渐偏离最快上升方向．当然，可以先走一段，然后重新计算最速上升方向，然后再走．这个方法看着不错，但是不实用．为什么呢？持续计算梯度需要很大计算量．</p>
<p>一种对这个的改进是，计算梯度只有在<span class="math inline">\(f(x,y)\)</span>停止增长以后．也就是首先沿初始梯度方向前进，直到<span class="math inline">\(f(x,y)\)</span>停止增长．然后在该点继续计算梯度，重新确定新的方向，重复这个过程，直到顶峰．－－最速上升法（steepest ascent optimisation algorithm）</p>
<blockquote>
<p>最速上升法例子</p>
</blockquote>
<p>利用初始值x=-1,y=-1求函数<span class="math inline">\(f(x,y)=2xy+2x-x^2-2y^2\)</span>最大值．</p>
<p>Step1: <span class="math inline">\(\begin{cases}\frac{\partial f}{\partial x}=2y+2-2x=0 \\ \frac{\partial f}{\partial y}=2x-4y=0 \end{cases} \Rightarrow x=2,\ y=1\)</span>, 并且该点是一个最大值． Step2: <span class="math inline">\(g(x_0+\Delta h,y_0+\Delta h)=-180h^2+72h-7\)</span>, 求解这个方程最大值：<span class="math inline">\(f&#39;(h^*)=0,\ h^*=0.2\)</span> Step3: 得到沿该梯度方向的最速点坐标 <span class="math inline">\(\begin{cases}x=x_0+\frac{\partial f}{\partial x}h=0.2 \\ y=y_0+\frac{\partial f}{\partial y}h=-0.2\end{cases}\)</span> Step4: 回到Step1,继续计算偏导数．直到收敛．</p>
<ol start="3" style="list-style-type: decimal">
<li>约束优化</li>
</ol>
<p>基本的线性规划问题：　<span class="math inline">\(\begin{cases}\text{Maximize } Z=c_1x_1+c_2x_2+..+c_nx_n \\ \text{Constraints }:　a_{i1}x_1+a_{i2}x_2+...+a_{in}x_n\le b_i \end{cases}\)</span>. 约束优化的问题就是如何解决在给定约束条件下的最优化问题．</p>
<p><span style="color:red"><strong><em>1) 理解最优化为什么会出现在工程问题中，出现在什么地方</em></strong></span></p>
<p>需要找到函数的最大值最小值</p>
<p><span style="color:red"><strong><em>2) 理解一般最优化问题的主要元素</em></strong></span></p>
<p>主要元素：全局最大值，局部最大值，全局最小值，局部最小值。</p>
<p><span style="color:red"><strong><em>3) 能够区分线性与非线性最优化问题，以及约束与无约束优化问题</em></strong></span></p>
<p>多维无约束优化，最直接的是随机搜索法。其次是梯度法，在其次是最快上升法。</p>
<p><span style="color:red"><strong><em>4) 能够定义黄金比例，并且懂得它如何使一维优化更有效</em></strong></span></p>
<p>黄金分割比例<span class="math inline">\(\frac{\sqrt{5}-1}{2}\)</span>. 但是黄金分割需要预先确定区间。</p>
<p><span style="color:red"><strong><em>5) 能够利用黄金分割搜索法、二次插值法以及牛顿法求单变量函数的最优值。同时，掌握如何权衡这些方法，特别注意的是初始估计值和收敛性</em></strong></span></p>
<p>二次插值利用3个点确定当前最优点，然后再次划分区间。速度快。</p>
<p><span style="color:red"><strong><em>6) 能够利用最速上升或下降法人工计算二元函数的最优值</em></strong></span></p>
<p>最快上升法的例子：利用初始估计值<span class="math inline">\(x=-1,y=1\)</span>求函数最大值。<span class="math inline">\(f(x,y)=2xy+2x-x^2-2y^2\)</span> 首先计算偏导数<span class="math inline">\(\begin{cases}\frac{\partial f}{\partial x}=2y+2-2x=0\\ \frac{\partial f}{\partial y}=2x-4y=0\end{cases}\)</span>得到最优值<span class="math inline">\(x=2,y=1\)</span>。 然后在最优值出计算二阶偏导数，得到<span class="math inline">\(\begin{cases}\frac{\partial^2 f}{\partial x^2}=-2\\\frac{\partial^2 f}{\partial y^2}=-4\\\frac{\partial^2 f}{\partial x \partial y}=\frac{\partial^2 f}{\partial y \partial x}=2\end{cases}\)</span></p>
<p>带入赫赛矩阵<span class="math inline">\(H=\begin{bmatrix}\frac{\partial^2 f}{\partial x^2}&amp;\frac{\partial^2 f}{\partial x \partial y}\\\frac{\partial^2 f}{\partial y \partial x} &amp; \frac{\partial^2 f}{\partial y^2}\end{bmatrix}\)</span>,得到<span class="math inline">\(|H|=4\)</span></p>
<p>由于<span class="math inline">\(|H|&gt;0,\frac{\partial f^2}{\partial x^2}&lt;0\)</span>， 所以函数值f(2,1)是最大值。</p>
<p>沿着梯度方向进行搜索，得到沿此轴的函数：<span class="math inline">\(f(x_0+\frac{\partial f}{\partial x}h,y_0+\frac{\partial f}{\partial y}h)=f(2+6h,1-6h)=-180h^2+72h-7\)</span>,求出最大值<span class="math inline">\(h^*=0.2\)</span>.</p>
<p>这表示，若沿着h轴前进，<span class="math inline">\(g(h)\)</span>在<span class="math inline">\(h^*=0.2\)</span>时达到一个最大值，带入得到新的坐标<span class="math inline">\((x,y)\)</span></p>
<p><span style="color:red"><strong><em>7) 理解共轭梯度法，牛顿法的基本思想</em></strong></span></p>
<p>牛顿法：<span class="math inline">\(x_{i+1}=x_i-\frac{f&#39;(x_i)}{f&#39;&#39;(x_i)}\)</span>。 原理是利用导数为0求解。</p>
</body>
</html>
