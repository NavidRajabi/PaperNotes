<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>PATTERN RECOGNITION AND MACHINE LEARNING</title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<div id="header">
<h1 class="title">PATTERN RECOGNITION AND MACHINE LEARNING</h1>
</div>
<!-- MarkdownTOC -->
<ul>
<li><a href="#网络爬虫">网络爬虫</a></li>
<li><a href="#模式分类">模式分类</a></li>
</ul>
<!-- /MarkdownTOC -->
<h2 id="网络爬虫">网络爬虫</h2>
<p><span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/column/details/why-bug.html">Python爬虫入门教程</a> / <a href="http://zhonghuan.info/2014/09/04/python网络爬虫学习笔记/">python网络爬虫学习笔记</a> / <a href="http://blog.pluskid.org/?p=366">Scrapy 轻松定制网络爬虫</a> / <a href="http://yongli1992.com/?p=146">Python爬虫模块Scrapy学习笔记</a> / <a href="http://www.uanswer.me/?/question/522">如何用python写爬虫抓取淘宝模特图片？</a> / <a href="https://jenny42.com/2015/02/write-a-spider-use-python/">写一个 Python 爬虫</a> / <a href="https://github.com/qhwlpg/taobaomei/blob/master/taobaomei.py">taobaomei/taobaomei.py</a> / <a href="http://sourceforge.net/projects/archive-crawler/files/archive-crawler%20(heritrix%201.x)/">Heritrix: Internet Archive Web Crawler</a> / <a href="http://www.ibeifeng.com/tech-69241.html">开源爬虫: Heritrix 1.14.4 安装/使用</a> / <a href="http://blog.csdn.net/orange_xxx/article/details/7764951">Eclipse中配置使用Heritrix-1.14.4</a> / <a href="http://www.linuxidc.com/Linux/2010-11/30104.htm">Project 1-1: Ubuntu下配置和运行Heritrix</a> / <a href="http://blog.sina.com.cn/s/blog_622a6fd601010ldt.html">heritrix初学笔记 Eclispe运行（四）</a> / <a href="http://blog.sina.com.cn/s/blog_5f54f0be0101hcy8.html">开源爬虫: Heritrix 1.14.4 安装/使用</a> / <a href="http://guoyunsky.iteye.com/category/82971">Heritrix源码分析</a> / <a href="http://www.cnblogs.com/cy163/p/3869175.html">83款 网络爬虫开源软件</a></p>
<h2 id="模式分类">模式分类</h2>
<ol style="list-style-type: decimal">
<li><p>贝叶斯决定论<br/> (1)贝叶斯决定论-连续特征<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/zhjm07054115/article/details/27631913">OpenCV Machine Learning 之 正态贝叶斯分类器 （Normal Bayes Classifier）</a> / <a href="http://blog.csdn.net/carson2005/article/details/6854024">openCV中贝叶斯分类器相关的API及其用法举例</a> / <a href="http://www.csdn123.com/html/exception/695/695370_695365_695363.htm">OpenCV Machine Learning 之正态贝叶斯分类器（Normal Bayes Classifier）的用法范例</a> / <a href="http://blog.csdn.net/godenlove007/article/details/8913007">OpenCV机器学习（1）：贝叶斯分类器实现代码分析</a> / <a href="http://blog.csdn.net/huangxy10/article/details/7597922">MFC中使用控制台输出调试信息</a> / <a href="http://www.cnblogs.com/bingcaihuang/archive/2011/03/12/1982170.html">在MFC，Win32程序中向控制台(Console)窗口输出调试信息</a> / <a href="http://blog.csdn.net/huangxy10/article/details/7597922">MFC中使用控制台输出调试信息</a> / <a href="http://www.cnblogs.com/wind-net/p/3153971.html">MFC下调用控制台和控制台下MFC库的支持</a> / <a href="http://blog.csdn.net/VisualEleven/article/details/5517541">MFC的GUI窗口使用Console输出函数printf</a> / <a href="http://m.blog.csdn.net/blog/everettjf/5931043">mfc中调用cout</a> / <a href="http://ygdljg.blog.163.com/blog/static/54601046200893042229423/">MFC中重载std::cout就可以使用cout</a> / <a href="http://www.cnblogs.com/emyueguang/archive/2011/08/11/2134562.html">MFC使用控制台</a></p>
<p>(2)贝叶斯决策论-离散特征<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/songzitea/article/details/23131609">贝叶斯(Bayes)决策理论</a> / <a href="http://blog.csdn.net/carson2005/article/details/6854005">贝叶斯理论简介</a> / <a href="http://www.pudn.com/downloads427/sourcecode/graph/text_recognize/detail1805874.html">基于OpenCV的皮肤检测算法实现，基于贝叶斯决策理论</a> / <a href="http://xiahouzuoxin.github.io/notes/html/Stanford机器学习课程笔记2-高斯判别分析与朴素贝叶斯.html">Stanford机器学习课程笔记2-高斯判别分析与朴素贝叶斯</a> / <a href="http://www.cnblogs.com/coser/archive/2013/05/06/3063937.html">基于最小错误率的贝叶斯决策</a> / <a href="http://blog.csdn.net/chasdmeng/article/details/38709063">EM算法求高斯混合模型参数估计——Python实现</a> / <a href="http://www.cncoders.net/article/17896/">模式识别：最大似然估计与贝叶斯估计方法</a></p>
<p>(3)复合贝叶斯决策论和上下文<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/carson2005/article/details/6854024/">openCV中贝叶斯分类器相关的API及其用法举例</a> / <a href="http://www.xuebuyuan.com/2178605.html">数据挖掘十大经典实用算法</a> / <a href="http://blog.csdn.net/angelazy/article/details/41947427">OpenCV的machine learning模块使用</a></p>
<p>(4)无监督贝叶斯学习<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/v_july_v/article/details/7577684">从决策树学习谈到贝叶斯分类算法、EM、HMM</a></p></li>
<li>分类<br/>
<ol style="list-style-type: decimal">
<li><p>最小误差概率分类<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/xiaowei_cqu/article/details/7670703">【OpenCV】基于Adaboost和Haar-like特征人脸识别</a> / <a href="http://blog.csdn.net/xiaowei_cqu/article/details/9004193">【模式识别】最小平方误差判别 MSE</a></p></li>
<li><p>分类器、判别函数及判定面<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/yang_xian521/article/details/6973667">OpenCV学习笔记（二十七）——基于级联分类器的目标检测objdect</a> / <a href="http://blog.csdn.net/yang_xian521/article/details/7031030">OpenCV学习笔记（三十三）——用haar特征训练自己的分类器（再做手势检测）</a> / <a href="http://wenjuanhe.blog.163.com/blog/static/745017252009102101728454/">分类器（模式识别）</a> / <a href="http://www.opencv.org.cn/opencvdoc/2.3.2/html/doc/tutorials/objdetect/cascade_classifier/cascade_classifier.html">级联分类器</a> / <a href="http://blog.csdn.net/timidsmile/article/details/6765164">如何用 opencv 训练自己的分类器</a></p></li>
<li><p>正态分布的判别函数<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/chlele0105/article/details/11786247">opencv高斯混合模型</a> / <a href="http://m.blog.csdn.net/blog/duliang_wu/7317740">opencv2.3混合高斯模型背景显示</a> / <a href="http://blog.csdn.net/wqvbjhc/article/details/5485242">混合高斯模型原理</a> / <a href="http://blog.csdn.net/chlele0105/article/details/11786247">opencv高斯混合模型</a> / <a href="http://blog.csdn.net/u010696366/article/details/30029445">OpenCV2.2 和 2.4.4 的 cvSetCaptureProperty 和 CvGaussBGModel （高斯背景建模）版本间差异</a> / <a href="http://blog.csdn.net/loadstar_kun/article/details/8548253">OpenCV_基于混合高斯模型GMM的运动目标检测</a> / <a href="http://zh.wikipedia.org/zh-cn/%D5%FD%CC%AC%B7%D6%B2%BC">高斯分布（Gaussian distribution）/正态分布（Normal distribution）</a></p></li>
<li><p>分类器中的重采样技术<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/carson2005/article/details/7981622">分类器中的重采样技术-bagging 和boosting</a></p></li>
<li><p>分类器的评价与比较<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/liyuefeilong/article/details/44604001">模式识别：分类器的性能评价</a></p></li>
<li><p>组合分类器<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/dianacody/article/details/40735161">【机器学习】分类器组合——AdaBoost</a></p></li>
<li><p>距离度量和最近邻分类<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://dataunion.org/4237.html">机器学习经典算法详解及Python实现–K近邻(KNN)算法</a> / <a href="http://blog.sina.com.cn/s/blog_7420820c0100pl87.html">多元统计分析(一)　马氏距离</a></p></li>
<li><p>模糊分类<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/superdont/article/details/46350837">python中使用mahotas包实现高斯模糊</a></p></li>
<li><p>线性判别函数与判定面<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://scikit-learn.org/stable/modules/generated/sklearn.lda.LDA.html">sklearn.lda.LDA</a> / <a href="http://dataunion.org/9366.html">机器学习中的数学(4)-线性判别分析（LDA）, 主成分分析(PCA)</a></p></li>
<li><p>广义线性判别函数<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_pca_vs_lda.html">Comparison of LDA and PCA 2D projection of Iris dataset</a></p></li>
<li><p>两类线性可分的情况<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/suipingsp/article/details/41645779">机器学习经典算法详解及Python实现--基于SMO的SVM分类器</a> / <a href="http://www.mblondel.org/journal/2010/09/19/support-vector-machines-in-python/">Support Vector Machines in Python</a> / <a href="https://code.google.com/p/haines/wiki/svm">Support Vector Machine</a> / <a href="http://blog.chinaunix.net/uid-28311809-id-4267135.html">SVM总结及SMO简单实现</a> / <a href="http://www.csie.ntu.edu.tw/~cjlin/libsvm/">LIBSVM -- A Library for Support Vector Machines</a> / <a href="http://liuhongjiang.github.io/tech/blog/2012/12/28/svm-smo/">SMO序列最小最优化算法</a> / https://github.com/liuhongjiang/blog_projects.git</p></li>
<li><p>感知器准则函数最小化<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/zouxy09/article/details/17589329">机器学习算法与Python实践之（五）k均值聚类（k-means）</a> / <a href="http://hujiaweibujidao.github.io/blog/2014/07/01/python-algorithms-graphs/">Python Algorithms - C9 Graphs</a> / <a href="http://www.jeapedu.com/blog/?p=335">最短路算法(Shortest Paths Algorithm)–zz</a></p></li>
<li><p>不可分的情况<br/></p></li>
<li><p>支持向量机<br/></p></li>
<li><p>判定树<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.cnblogs.com/yysblog/p/3318511.html">Decision Tree</a> / <a href="http://dataunion.org/5771.html">机器学习经典算法详解及Python实现–CART分类决策树、回归树和模型树</a> / <a href="http://blog.csdn.net/suipingsp/article/details/41927247">机器学习经典算法详解及Python实现--决策树（Decision Tree）</a></p></li>
</ol></li>
<li><p>丢失特征和噪声特征<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/chenyusiyuan/article/details/8715129">KAZE 算法原理与源码分析（四）KAZE特征的性能分析与比较</a> / <a href="http://www.cnblogs.com/tornadomeet/archive/2012/12/05/2802428.html">基础学习笔记之opencv(21)：一个简单有趣的皮肤检测代码</a></p></li>
<li><p>最大似然估计<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/crzy_sparrow/article/details/7413019" class="uri">http://blog.csdn.net/crzy_sparrow/article/details/7413019</a> / <a href="http://blog.csdn.net/zouxy09/article/details/8537620">从最大似然到EM算法浅解</a> / <a href="http://blog.sina.com.cn/s/blog_4513dde60100o6nb.html">用最大似然估计的方法来估计频率</a> / <a href="http://blog.csdn.net/buptgshengod/article/details/38817621">【机器学习算法-python实现】最大似然估计(Maximum Likelihood)</a> / <a href="http://xccds1977.blogspot.sg/2012_08_01_archive.html">EM算法的R实现和高斯混合模型</a></p></li>
<li><p>充分统计量<br/> <span style="color:red"><strong>Reference:</strong></span> / <a href="http://blog.sina.com.cn/s/blog_5033f3b40101g2ur.html">sufficient statistic 充分统计量</a> / <a href="http://www.cnblogs.com/ysjxw/archive/2008/10/29/1322170.html">充分统计量(Sufficient Statistics)</a> / <a href="http://blog.hit.edu.cn/jiangfeng/post/31.html">怎样理解充分统计量（sufficient statistic）</a></p></li>
<li>成分分析和判别函数<br/>
<ol style="list-style-type: decimal">
<li>成分分析<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.cnblogs.com/chenbjin/p/4200790.html">Python 主成分分析PCA</a> / <a href="http://m.blog.csdn.net/blog/u013128965/26595983">OpenCV之PCA（主成分分析）</a> / <a href="http://blog.sina.com.cn/s/blog_75e063c101014aob.html">PCA的系统分析（包括PCA原理/opencv的PCA函数内部原理和应用/matlab程序）</a> / <a href="http://blog.sina.com.cn/s/blog_61c463090100mj7n.html">python 主成分分析</a> / <a href="http://www.tuicool.com/articles/7nIvum">【机器学习算法-python实现】PCA 主成分分析、降维</a> / <a href="http://www.cnblogs.com/oskycar/articles/1385755.html">OpenCV统计应用-PCA主成分分析</a> / <a href="http://www.mamicode.com/info-detail-659716.html">主成分分析法原理及其python实现</a> / <a href="http://blog.csdn.net/rav009/article/details/13170725">高维数据的应对手段: 主成分分析(PCA)简介/numpy实现/weka使用说明</a></li>
</ol></li>
<li><p>期望最大化算法<br/> <span style="color:red"><strong>Reference:</strong></span> / <a href="http://www.open-open.com/lib/view/open1421284692937.html">机器学习经典算法详解及Python实现--聚类及K均值、二分K-均值聚类算法</a> / <a href="http://www.52ml.net/tags/最大期望算法">EM算法 – 浪子散仙</a> / <a href="http://www.bkjia.com/yjs/831817.html">K-means无监督学习实现分类，-pythonk-means</a> / <a href="http://dataunion.org/7781.html">机器学习经典算法详解及Python实现——聚类及K均值、二分K-均值聚类算法</a></p></li>
<li><p>隐马尔科夫模型<br/> <span style="color:red"><strong>Reference:</strong></span> / <a href="http://www.cnblogs.com/zhiranok/archive/2012/12/15/ymrkf_viterbi.html">隐马尔科夫-维特比算法</a> / <a href="http://www.zhihu.com/question/20962240">如何用简单易懂的例子解释隐马尔可夫模型？</a></p></li>
<li><p>非参数技术<br/> <span style="color:red"><strong>Reference:</strong></span> / <a href="http://www.aliog.com/1721.html">GMM算法（Python版）</a> / <a href="http://blog.csdn.net/abcjennifer/article/details/8198352">GMM的EM算法实现</a> / <a href="http://www.4byte.cn/question/966579/histogram-based-probability-density-estimation.html">基于概率密度估计的直方图</a></p></li>
<li><p>Parzen window<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.cnblogs.com/chenbjin/p/3861477.html">Python KNN算法</a> / <a href="http://blog.csdn.net/jkhere/article/details/8757393">Parzen窗估计</a> / <a href="http://sebastianraschka.com/Articles/2014_parzen_density_est.html">Kernel density estimation via the Parzen–Rosenblatt window method</a></p></li>
<li><p>KN-近邻估计<br/> <span style="color:red"><strong>Reference:</strong></span> / <a href="http://scikit-learn.org/stable/modules/neighbors.html">1.6. Nearest Neighbors</a> / <a href="http://scikit-learn.org/dev/install.html">sklearn.base: Base classes and utility functions</a> / <a href="http://sebastianraschka.com/Articles/2014_parzen_density_est.html">Kernel density estimation via the Parzen–Rosenblatt window method</a> / <a href="http://machinelearningmastery.com/tutorial-to-implement-k-nearest-neighbors-in-python-from-scratch/">Tutorial To Implement k-Nearest Neighbors in Python From Scratch</a> / <a href="http://scikit-learn.org/dev/install.html">Installing scikit-learn</a> / <a href="https://jakevdp.github.io/blog/2013/04/29/benchmarking-nearest-neighbor-searches-in-python/">Benchmarking Nearest Neighbor Searches in Python</a></p></li>
<li><p>RCE网络<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.oschina.net/translate/python-web-framework-from-lfr-to-rce">Python Web框架会话管理：从LFR到RCE</a></p></li>
<li>松弛算法<br/></li>
<li><p>Ho-Kashyap算法<br/></p></li>
<li><p>线性规划算法<br/></p></li>
<li><p>多层神经网络<br/></p>
<ol style="list-style-type: decimal">
<li>前馈运算和分类<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.open-open.com/lib/view/open1419757875218.html">学习Python来分类现实世界的数据</a></li>
</ol>
<p>(2)反向传播算法<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.sina.com.cn/s/blog_9dc1f5e3010101bl.html">多层神经网络及反向传播算法</a> / <a href="http://www.zhihu.com/question/24827633/answer/29189075">如何理解神经网络里面的反向传播算法？</a> / <a href="http://www.cnblogs.com/phinecos/archive/2008/10/18/1314181.html">人工神经网络之反向传播算法</a></p>
<p>(3)误差曲面<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://hyry.dip.jp/tech/book/page/scipynew/scipy-310-optimize.html">拟合与优化-optimize</a></p>
<p>(4)反向传播作为特征映射<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://dataunion.org/9822.html">深入探究递归神经网络RNN：大牛级的训练和优化</a> / <a href="http://dataunion.org/11692.html">技术向：一文读懂卷积神经网络CNN</a> / <a href="http://blog.csdn.net/zouxy09/article/details/8781543">Deep Learning（深度学习）学习笔记整理系列之（七）</a> / <a href="http://blog.csdn.net/sloudy/article/details/45956037">Convolutional Neural Network--学习与实践</a> / <a href="https://victorfang.wordpress.com/2014/04/">Deep learning：五十一(CNN的反向求导及练习)</a></p>
<p>(5)反向传播、贝叶斯理论和概率<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://python.jobbole.com/81019/">机器学习之用Python从零实现贝叶斯分类器</a> / <a href="http://blog.csdn.net/xietingcandice/article/details/44096439">机器学习 Python实现 贝叶斯算法</a> / <a href="http://www.bkjia.com/yjs/1008354.html">机器学习算法-朴素贝叶斯Python实现，算法贝叶斯python</a> / <a href="http://www.bkjia.com/ASPjc/892063.html">朴素贝叶斯python实现，贝叶斯python</a></p>
<p>(6)改进反向传播的一些实用技术<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="https://github.com/YauzZ/searchengine">中文分词支持，可以对中文网页进行抓取。</a> / <a href="http://wenku.baidu.com/view/2dfa34fbfab069dc50220190.html">神经网络介绍—利用反向传播算法的模式学习</a></p>
<p>(7)二阶技术<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.cnblogs.com/lancelod/p/4062352.html">用于加速训练神经网络的二阶方法</a></p>
<p>(8)正则化、复杂度调节和剪枝<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="https://www.v2ex.com/t/170197">snakefood——可视化 python 代码复杂度</a> / <a href="http://shikezhi.com/html/2015/python_0531/17928.html">用Python代码来解图片迷宫的方法整理</a></p>
<p>(9)随机搜索<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.pythontab.com/html/2013/pythonhexinbiancheng_0530/422.html">python抓取google搜索结果</a> / <a href="http://blog.csdn.net/jgood/article/details/4278885">Python模块学习 ---- random 随机数生成</a></p></li>
<li><p>Boltzman学习<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://scikit-learn.org/stable/modules/neural_networks.html">2.9. Neural network models (unsupervised)</a></p></li>
<li><p>遗传规划<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.yebohe.cn/article/11eb9025950698c222cdb798051e2fb9/">一些好的遗传编程库在Python中是什么？</a></p></li>
<li><p>CART<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://scikit-learn.org/stable/modules/tree.html">1.10. Decision Trees</a> / <a href="http://machinelearningmastery.com/a-gentle-introduction-to-scikit-learn-a-python-machine-learning-library/">A Gentle Introduction to Scikit-Learn: A Python Machine Learning Library</a></p></li>
<li>字符识别<br/>
<ol style="list-style-type: decimal">
<li><p>串的识别<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://yangsq.iteye.com/blog/142325">python 字符串中的中文识别</a></p></li>
<li><p>文法推断<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://d.wanfangdata.com.cn/periodical_jsjyjyfz201310002.aspx">基于文法推断的协议逆向工程</a></p></li>
<li><p>基于规则的方法<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://book.douban.com/subject/25916599/">Python自然语言处理</a></p></li>
</ol></li>
<li><p>偏差和方差<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.cnblogs.com/leftnoteasy/archive/2010/12/19/mathmatic_in_machine_learning_2_regression_and_bias_variance_trade_off.html">机器学习中的数学(2)-线性回归，偏差、方差权衡</a> / <a href="http://leftnoteasy.cnblogs.com">关注于 机器学习、数据挖掘、并行计算、数学</a></p></li>
<li><p>统计量估计中的重采样技术<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/carson2005/article/details/7931135">统计量估计中的重采样技术</a></p></li>
<li><p>对混合正态密度的应用<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://jasonding1354.github.io/2015/02/10/Machine%20Learning/【机器学习中的数学】比例混合分布/">比例混合分布(Scale Mixture Distribution)</a></p></li>
<li><p>数据描述和聚类<br/></p>
<ol style="list-style-type: decimal">
<li><p>聚类的准则函数<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.llwjy.com/blogdetail/41b268618a679a6ec9652f3635432057.html">文本聚类算法介绍</a> / <a href="http://dataunion.org/7248.html">数据可挖掘的知识类型：概念/类描述、关联模式、聚类分析…</a> / <a href="http://dataunion.org/7781.html">机器学习经典算法详解及Python实现——聚类及K均值、二分K-均值聚类算法</a></p></li>
<li><p>迭代最优化<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://www.cnblogs.com/daniel-D/p/3377840.html">机器学习中导数最优化方法(基础篇)</a></p></li>
<li><p>层次聚类<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/v_july_v/article/details/7577684">Python层次聚类</a> / <a href="http://www.cnblogs.com/Key-Ky/p/3440684.html">Python-层次聚类-Hierarchical clustering</a></p></li>
<li><p>在线聚类<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://bbs.pinggu.org/thread-3664965-1-1.html">浅谈聚类分析的几种算法</a> / <a href="http://www.oschina.net/code/snippet_176897_14732">初识聚类算法: 凝聚层次聚类</a></p></li>
</ol></li>
<li><p>图论方法<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://blog.csdn.net/u010352695/article/details/44678519">python 图论算法（一）</a></p></li>
<li><p>低维数据表示和多维尺度变换<br/> <span style="color:red"><strong>Reference:</strong></span> <a href="http://chunqiu.blog.ustc.edu.cn/?p=444">多维尺度变换</a> / <a href="http://lixinzhang.github.io/pai-xu-xue-xi-learning-to-rank.html">排序学习（Learning to Rank）</a></p></li>
</ol>
</body>
</html>
