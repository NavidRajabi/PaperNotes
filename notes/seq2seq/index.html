<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title>Sequence-to-Sequence models</title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="pandoc.css" type="text/css" />
</head>
<body>
<div id="header">
<h1 class="title">Sequence-to-Sequence models</h1>
</div>
<center>
Update: 06/04/2018_14:18:21
</center>
<ol style="list-style-type: decimal">
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/Thesis---Contributions.html">Thesis - Contributions</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Stable-and-Effective-Trainable-Greedy-Decoding-for-Sequence-to-Sequence-Learning.html">Stable and Effective Trainable Greedy Decoding for Sequence to Sequence Learning</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Soft-Actor-Critic-Off-Policy-Maximum-Entropy-Deep-Reinforcement-Learning-with-a-Stochastic-Actor.html">Soft Actor-Critic</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-SEARNN-Training-RNNs-with-global-local-losses.html">{SEARNN}</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Neural-Lattice-Language-Models.html">Neural Lattice Language Models</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-MaskGAN-Better-Text-Generation-via-Filling-in-the.html">MaskGAN</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Generating-Contradictory-Neutral-and-Entailing-Sentences.html">Generating Contradictory, Neutral, and Entailing Sentences</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Discrete-Autoencoders-for-Sequence-Models.html">Discrete Autoencoders for Sequence Models</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Differentiable-Dynamic-Programming-for-Structured-Prediction-and-Attention.html">Differentiable Dynamic Programming for Structured Prediction and</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Deterministic-Non-Autoregressive-Neural-Sequence-Modeling-by-Iterative-Refinement.html">Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model.html">Breaking the Softmax Bottleneck</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Bi-Directional-Block-Self-Attention-for-Fast-and-Memory-Efficient-Sequence-Modeling.html">Bi-Directional Block Self-Attention for Fast and Memory-Efficient Sequence</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Using-stochastic-computation-graphs-formalism-for-optimization-of-sequence-to-sequence-model.html">Using stochastic computation graphs formalism for optimization of sequence-to-sequence model</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Translating-Phrases-in-Neural-Machine-Translation.html">Translating Phrases in Neural Machine Translation</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Towards-Neural-Phrase-based-Machine-Translation.html">Towards Neural Phrase-based Machine Translation</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Synthetic-and-Natural-Noise-Both-Break-Neural-Machine-Translation.html">Synthetic and Natural Noise Both Break Neural Machine Translation</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Sequence-Modeling-via-Segmentations.html">Sequence Modeling via Segmentations</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Differentiable-lower-bound-for-expected-BLEU-score.html">Differentiable lower bound for expected BLEU score</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Data-Noising-as-Smoothing-in-Neural-Network-Language-Models.html">Data Noising as Smoothing in Neural Network Language Models</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Comparative-Study-of-CNN-and-RNN-for-Natural-Language-Processing.html">Comparative Study of CNN and RNN for Natural Language Processing</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Classical-Structured-Prediction-Losses-for-Sequence-to-Sequence-Learning.html">Classical Structured Prediction Losses for Sequence to Sequence Learning</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2016-Reward-Augmented-Maximum-Likelihood-for-Neural-Structured-Prediction.html">Reward Augmented Maximum Likelihood for Neural Structured Prediction</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2016-Multimodal-Pivots-for-Image-Caption-Translation.html">Multimodal Pivots for Image Caption Translation</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2016-An-Actor-Critic-Algorithm-for-Sequence-Prediction.html">An Actor-Critic Algorithm for Sequence Prediction</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2015-Sequence-Level-Training-with-Recurrent-Neural-Networks.html">Sequence Level Training with Recurrent Neural Networks</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2015-Scheduled-Sampling-for-Sequence-Prediction-with-Recurrent-Neural-Networks.html">Scheduled Sampling for Sequence Prediction with Recurrent Neural</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2015-Neural-Machine-Translation-of-Rare-Words-with-Subword-Units.html">Neural Machine Translation of Rare Words with Subword Units</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2015-Minimum-Risk-Training-for-Neural-Machine-Translation.html">Minimum Risk Training for Neural Machine Translation</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2014-Sequence-to-Sequence-Learning-with-Neural-Networks.html">Sequence to Sequence Learning with Neural Networks</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2014-On-Using-Very-Large-Target-Vocabulary-for-Neural-Machine-Translation.html">On Using Very Large Target Vocabulary for Neural Machine Translation</a></li>
<li><a href="https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2014-Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate.html">Neural Machine Translation by Jointly Learning to Align and Translate</a></li>
</ol>
</body>
</html>
