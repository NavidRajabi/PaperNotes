---
layout: post
title:  "Sequence-to-Sequence models"
category: Deep learning
tags: [DL, NLP, CV, CL]
---





<center> Update: 01/03/2018_13:59:35</center>

  	
1. [ Discrete Autoencoders for Sequence Models](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Discrete-Autoencoders-for-Sequence-Models.html)
2. [ 'Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Deterministic-Non-Autoregressive-Neural-Sequence-Modeling-by-Iterative-Refinement.html)
3. [ International Conference on Learning Representations 'Breaking the Softmax Bottleneck](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2018-Breaking-the-Softmax-Bottleneck-A-High-Rank-RNN-Language-Model.html)
4. [ 'Using stochastic computation graphs formalism for optimization of](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Using-stochastic-computation-graphs-formalism-for-optimization-of-sequence-to-sequence-model.html)
5. [ Translating Phrases in Neural Machine Translation](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Translating-Phrases-in-Neural-Machine-Translation.html)
6. [ Towards Neural Phrase-based Machine Translation](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Towards-Neural-Phrase-based-Machine-Translation.html)
7. [ Synthetic and Natural Noise Both Break Neural Machine Translation](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Synthetic-and-Natural-Noise-Both-Break-Neural-Machine-Translation.html)
8. [ Sequence Modeling via Segmentations](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Sequence-Modeling-via-Segmentations.html)
9. [ Differentiable lower bound for expected BLEU score](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2017-Differentiable-lower-bound-for-expected-BLEU-score.html)
10. [ Sequence Level Training with Recurrent Neural Networks](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2015-Sequence-Level-Training-with-Recurrent-Neural-Networks.html)
11. [ Minimum Risk Training for Neural Machine Translation](https://rawgit.com/elbayadm/PaperNotes/master/notes/seq2seq/2015-Minimum-Risk-Training-for-Neural-Machine-Translation.html)
